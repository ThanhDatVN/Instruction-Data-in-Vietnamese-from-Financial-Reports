{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fbde7d4",
   "metadata": {},
   "source": [
    "## Chuyá»ƒn pdf Ä‘Ã£ convert tá»« pdf scan sang text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02de58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Äá»‹nh nghÄ©a thÆ° má»¥c Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra\n",
    "PDF_FOLDER = \"folder_2_converted\"\n",
    "TXT_FOLDER = \"folder_2_txt\"\n",
    "LOG_FILE = \"extract_pdf_log.txt\"\n",
    "\n",
    "# Táº¡o thÆ° má»¥c TXT náº¿u chÆ°a tá»“n táº¡i\n",
    "os.makedirs(TXT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Ghi log\n",
    "def write_log(message, log_file=LOG_FILE):\n",
    "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "\n",
    "# HÃ m trÃ­ch xuáº¥t text tá»« má»™t file PDF\n",
    "def extract_text_from_pdf(pdf_path: Path):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() or \"\"  # TrÃ­ch xuáº¥t text tá»« má»—i trang, bá» qua náº¿u None\n",
    "            # Chuáº©n hÃ³a text: loáº¡i bá» khoáº£ng tráº¯ng thá»«a\n",
    "            text = \"\\n\".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ Lá»—i trÃ­ch xuáº¥t PDF {pdf_path.name}: {e}\"\n",
    "        write_log(error_msg)\n",
    "        print(error_msg)\n",
    "        return None\n",
    "\n",
    "# LÆ°u text vÃ o file TXT\n",
    "def save_text_to_txt(pdf_path: Path, text: str):\n",
    "    txt_filename = pdf_path.stem + \".txt\"  # Giá»¯ nguyÃªn tÃªn file, thay Ä‘uÃ´i .pdf thÃ nh .txt\n",
    "    txt_path = Path(TXT_FOLDER) / txt_filename\n",
    "    try:\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "        log_msg = f\"âœ… ÄÃ£ lÆ°u text tá»« {pdf_path.name} vÃ o {txt_path}\"\n",
    "        write_log(log_msg)\n",
    "        print(log_msg)\n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ Lá»—i lÆ°u file {txt_path.name}: {e}\"\n",
    "        write_log(error_msg)\n",
    "        print(error_msg)\n",
    "\n",
    "# Xá»­ lÃ½ song song cÃ¡c file PDF\n",
    "def extract_all_pdfs_concurrently(max_workers=4):\n",
    "    pdf_files = list(Path(PDF_FOLDER).glob(\"*.pdf\"))\n",
    "    if not pdf_files:\n",
    "        log_msg = \"ğŸ“‚ KhÃ´ng cÃ³ file PDF nÃ o trong thÆ° má»¥c folder_1_converted.\"\n",
    "        write_log(log_msg)\n",
    "        print(log_msg)\n",
    "        return\n",
    "\n",
    "    log_msg = f\"ğŸš€ Sá»‘ file PDF cáº§n trÃ­ch xuáº¥t: {len(pdf_files)}\"\n",
    "    write_log(log_msg)\n",
    "    print(log_msg)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Táº¡o mapping future -> pdf_file\n",
    "        future_to_pdf = {executor.submit(extract_text_from_pdf, pdf_file): pdf_file for pdf_file in pdf_files}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_pdf):\n",
    "            pdf_file = future_to_pdf[future]\n",
    "            try:\n",
    "                text = future.result()\n",
    "                if text:\n",
    "                    save_text_to_txt(pdf_file, text)\n",
    "            except Exception as e:\n",
    "                error_msg = f\"âŒ Lá»—i xá»­ lÃ½ {pdf_file.name}: {e}\"\n",
    "                write_log(error_msg)\n",
    "                print(error_msg)\n",
    "\n",
    "# Cháº¡y pháº§n trÃ­ch xuáº¥t\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    extract_all_pdfs_concurrently(max_workers=4)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    log_msg = f\"â±ï¸ HoÃ n táº¥t trÃ­ch xuáº¥t PDF! Tá»•ng thá»i gian: {elapsed_time:.2f} giÃ¢y\"\n",
    "    write_log(log_msg)\n",
    "    print(log_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e82583",
   "metadata": {},
   "source": [
    "## Sinh chunk cho dá»¯ liá»‡u txt, nÃªn cháº¡y láº¡i vÃ i láº§n hoáº·c kiá»ƒm tra trÆ°á»›c báº±ng code bÃªn dÆ°á»›i Ä‘á»ƒ xem cÃ³ Ä‘á»§ sá»‘ file khÃ´ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2fcbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tuan Anh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tá»•ng sá»‘ API keys: 9\n",
      "Key 1: AIzaSyDurEPeaKYb1F9rCcF1rOY2-Et3VtPIJLg\n",
      "Key 2: AIzaSyDYjG9Z_fj4zttInrUm3wk7f7aKawpm3qE\n",
      "Key 3: AIzaSyDV9f9gyCt1-pbU-AX3HaYZrxMA417-Se4\n",
      "Key 4: AIzaSyDQClTO07TsamAs2vXuk_-s0EjX8GTEwvU\n",
      "Key 5: AIzaSyBO_S3_xvW4NmTU93Wsp9pnBVKNXe12O0A\n",
      "Key 6: AIzaSyAZnDLm3tcEfilmvdJVZCNMol_8ezR3Nj4\n",
      "Key 7: AIzaSyAt4K0VMxBmE80qWnyV_wAuSV5P5B4Rdq8\n",
      "Key 8: AIzaSyBk-Z6rGVq0bxqP_F_GgjFK1deMeqmVYco\n",
      "Key 9: AIzaSyBnjpOb7nJWOtQ_6m7031gm9vr8shIy-SQ\n",
      "9 API keys Ä‘Æ°á»£c tÃ¬m tháº¥y.\n",
      "ğŸš€ Tá»•ng sá»‘ file cáº§n xá»­ lÃ½: 6\n",
      "ğŸ“Œ Sáº½ xá»­ lÃ½ 6 file (bao gá»“m lá»—i, incomplete & chÆ°a cÃ³).\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459170_EN__SeparateFinancialStatements_Q4_2024.txt\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459603_EN_FinacialStatemants_Q4_2024.Holding_Company.txt\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.txt\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c text tá»«: folder_2.5_txt\\000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.txt\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c text tá»«: folder_2.5_txt\\000000014459603_EN_FinacialStatemants_Q4_2024.Holding_Company.txt\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c text tá»«: folder_2.5_txt\\000000014459170_EN__SeparateFinancialStatements_Q4_2024.txt\n",
      "âœ… LÆ°u JSON thÃ nh cÃ´ng (chuáº©n format): folder_2.5_step1\\000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459629_EN_FinacialStatements_Q4_2024_Final.signed.txt\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c text tá»«: folder_2.5_txt\\000000014459629_EN_FinacialStatements_Q4_2024_Final.signed.txt\n",
      "âœ… LÆ°u JSON thÃ nh cÃ´ng (chuáº©n format): folder_2.5_step1\\000000014459170_EN__SeparateFinancialStatements_Q4_2024.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.txt\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c text tá»«: folder_2.5_txt\\000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.txt\n",
      "âœ… LÆ°u JSON thÃ nh cÃ´ng (chuáº©n format): folder_2.5_step1\\000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.txt\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c text tá»«: folder_2.5_txt\\000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.txt\n",
      "ğŸ›‘ ÄÃ£ ghi log lá»—i cho 000000014459603_EN_FinacialStatemants_Q4_2024.Holding_Company.txt\n",
      "âœ… LÆ°u JSON thÃ nh cÃ´ng (chuáº©n format): folder_2.5_step1\\000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json\n",
      "ğŸ›‘ ÄÃ£ ghi log lá»—i cho 000000014459629_EN_FinacialStatements_Q4_2024_Final.signed.txt\n",
      "\n",
      "â±ï¸ Xong! Tá»•ng thá»i gian: 815.60 giÃ¢y\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import re\n",
    "from itertools import cycle\n",
    "import time\n",
    "\n",
    "# Táº£i biáº¿n mÃ´i trÆ°á»ng tá»« .env\n",
    "load_dotenv()\n",
    "\n",
    "# Láº¥y API keys tá»« .env vÃ  tÃ¡ch thÃ nh list\n",
    "API_KEYS = os.getenv(\"API_KEYS\", \"\").replace('\"', '').split(\",\")\n",
    "\n",
    "# Kiá»ƒm tra API keys\n",
    "print(f\"Tá»•ng sá»‘ API keys: {len(API_KEYS)}\")\n",
    "for i, key in enumerate(API_KEYS, 1):\n",
    "    print(f\"Key {i}: {key}\")\n",
    "\n",
    "NUM_THREADS = 3\n",
    "if len(API_KEYS) < NUM_THREADS:\n",
    "    raise ValueError(f\"âŒ Cáº§n Ã­t nháº¥t {NUM_THREADS} API keys, hiá»‡n táº¡i chá»‰ cÃ³ {len(API_KEYS)}.\")\n",
    "\n",
    "print(len(API_KEYS), \"API keys Ä‘Æ°á»£c tÃ¬m tháº¥y.\")\n",
    "\n",
    "# Chia API_KEYS thÃ nh cÃ¡c nhÃ³m cho má»—i thread\n",
    "def split_api_keys(keys, num_threads):\n",
    "    groups = [[] for _ in range(num_threads)]\n",
    "    for idx, key in enumerate(keys):\n",
    "        groups[idx % num_threads].append(key)\n",
    "    return groups\n",
    "\n",
    "api_key_groups = split_api_keys(API_KEYS, NUM_THREADS)\n",
    "\n",
    "# Cáº¥u hÃ¬nh thÆ° má»¥c\n",
    "OUTPUT_FOLDER = \"folder_2.5_step1\"\n",
    "EXTRACTED_TXT_FOLDER = \"folder_2.5_txt\"\n",
    "ERROR_LOG = \"error_log_step1.jsonl\"\n",
    "INCOMPLETE_LOG = \"incomplete_log_step1.jsonl\"\n",
    "\n",
    "# Äá»‹nh nghÄ©a instruction\n",
    "INSTRUCTION = \"\"\"\n",
    "Báº¡n lÃ  má»™t há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u bÃ¡o cÃ¡o tÃ i chÃ­nh.\n",
    "Nhiá»‡m vá»¥ cá»§a báº¡n: Nháº­n toÃ n bá»™ ná»™i dung cá»§a má»™t bÃ¡o cÃ¡o tÃ i chÃ­nh vÃ  chia thÃ nh cÃ¡c Ä‘oáº¡n (chunk) 400â€“800 token (dÆ°á»›i 1500 kÃ½ tá»±), thá»© hai lÃ  bÃ¡o cÃ¡o trÃ­ch xuáº¥t qua OCR vÃ  pdfplumber nÃªn sáº½ cÃ³ nhiá»u lá»—i chÃ­nh táº£, hÃ£y sá»­a nÃ³\n",
    "Quy táº¯c chia chunk:\n",
    "1. Má»—i chunk pháº£i chá»©a Ä‘áº§y Ä‘á»§ thÃ´ng tin ngá»¯ cáº£nh:\n",
    "- TÃªn cÃ´ng ty\n",
    "- MÃ£ cá»• phiáº¿u (VD: AAH)\n",
    "- Loáº¡i bÃ¡o cÃ¡o: há»£p nháº¥t, riÃªng, quÃ½, thÆ°á»ng niÃªn, bÃ¡n niÃªn, cÃ´ng bá»‘ thÃ´ng tin\n",
    "- Thá»i gian: ngÃ y phÃ¡t hÃ nh vÃ /hoáº·c quÃ½/nÄƒm (VD: 20/07/2025, Q2 2025)\n",
    "- Ã kiáº¿n kiá»ƒm toÃ¡n:\n",
    "    + Cháº¥p nháº­n toÃ n pháº§n\n",
    "    + Ngoáº¡i trá»«\n",
    "    + KhÃ´ng cháº¥p nháº­n\n",
    "    + Tá»« chá»‘i\n",
    "    + KhÃ´ng cÃ³\n",
    "- Ngáº¯n gá»n nhÆ°ng Ä‘á»§ thÃ´ng tin ngá»¯ cáº£nh.\n",
    "2. Báº£ng sá»‘ liá»‡u:\n",
    "- Náº¿u báº£ng khÃ´ng quÃ¡ dÃ i â†’ giá»¯ nguyÃªn trong chunk.\n",
    "- Náº¿u báº£ng quÃ¡ dÃ i â†’ cáº¯t há»£p lÃ½, giá»¯ pháº§n liÃªn quan.\n",
    "- Äáº£m báº£o pháº£i giá»¯ báº£ng Ä‘áº§y Ä‘á»§, khÃ´ng thiáº¿u thÃ´ng tin, báº£ng pháº£i theo cáº¥u trÃºc cá»§a cÃ¡c báº£ng trong bÃ¡o cÃ¡o tÃ i chÃ­nh, náº¿u báº£ng thiáº¿u thÃ¬ Ä‘iá»n dáº¥u '-' vÃ o.\n",
    "- KhÃ´ng bá»‹a thÃ´ng tin, cÃ¡i gÃ¬ khÃ´ng cÃ³ trong bÃ¡o cÃ¡o thÃ¬ ghi lÃ  khÃ´ng cÃ³, trÃ¡nh táº¡o thÃ´ng tin sai cho mÃ´ hÃ¬nh.\n",
    "- KhÃ´ng xuá»‘ng dÃ²ng trong JSON â†’ dÃ¹ng \\n thay cho line break tháº­t.\n",
    "- Náº¿u báº£ng hoáº·c vÄƒn báº£n quÃ¡ dÃ i thÃ¬ chia 2-3 báº£ng má»™t cÃ¡ch há»£p lÃ½, báº£ng cÃ¢n Ä‘á»‘i káº¿ toÃ¡n chia lÃ m 3 báº£ng lÃ  A(TÃ i sáº£n ngáº¯n háº¡n), B(TÃ i sáº£n dÃ i háº¡n), C(Ná»£) vÃ  D(Vá»‘n chá»§ sá»Ÿ há»¯u) thÃ¬ gá»™p chung, Báº£ng bÃ¡o cÃ¡o káº¿t quáº£ kinh doanh vÃ  luu chuyá»ƒn tiá»n tá»‡ thÃ¬ cÃ³ thá»ƒ Ä‘á»ƒ riÃªng láº» khÃ´ng cáº§n cáº¯t, thuyáº¿t minh bÃ¡o cÃ¡o tÃ i chÃ­nh thÃ¬ chia ra cÃ¡c Ä‘oáº¡n há»£p lÃ½ Ä‘á»§ Ä‘á»™ dÃ i vÃ  ngá»¯ cáº£nh, cÃ¡c báº£ng bÃ© trong thuyáº¿t minh bÃ¡o cÃ¡o tÃ i chÃ­nh cÃ³ thá»ƒ gá»™p láº¡i Ä‘á»ƒ cÃ³ Ä‘á»™ dÃ i há»£p lÃ½ trÃ¡nh 1 chunk cÃ³ báº£ng quÃ¡ ngáº¯n khÃ´ng cÃ³ thÃ´ng tin.\n",
    "3. CÃ¢u há»i cho má»—i chunk\n",
    "- Má»—i chunk kÃ¨m 3â€“6 cÃ¢u há»i cÃ³ thá»ƒ tráº£ lá»i trá»±c tiáº¿p tá»« chunk Ä‘Ã³:\n",
    "    + 1-2 cÃ¢u dá»… (QA, NER): trÃ­ch xuáº¥t trá»±c tiáº¿p (VD: doanh thu, ná»£, tÃªn cÃ´ng ty, mÃ£ cá»• phiáº¿u).\n",
    "    + 2â€“4 cÃ¢u trung bÃ¬nh (QA, SA): phÃ¢n tÃ­ch hoáº·c so sÃ¡nh cÆ¡ báº£n (VD: nÄƒm nÃ y vs nÄƒm trÆ°á»›c, phÃ¢n tÃ­ch tÃ¢m lÃ½ tÃ i chÃ­nh).\n",
    "    + 3-5 cÃ¢u khÃ³ (QA, SA): tá»•ng há»£p hoáº·c phÃ¢n tÃ­ch phá»©c táº¡p (VD: Ä‘Ã¡nh giÃ¡ sá»©c khá»e tÃ i chÃ­nh, rá»§i ro).\n",
    "- Chá»§ Ä‘á» cÃ¢u há»i cÃ³ thá»ƒ bao gá»“m: Nguá»“n vá»‘n, TÃ i sáº£n, Doanh thu, Chi phÃ­, LÆ°u chuyá»ƒn tiá»n tá»‡, Chá»‰ sá»‘ tÃ i chÃ­nh, TÃ¬nh hÃ¬nh tá»•ng thá»ƒ, Sá»± kiá»‡n Ä‘áº·c biá»‡t, Dá»± bÃ¡o, Rá»§i ro.\n",
    "- Má»—i cÃ¢u há»i loáº¡i nÃ o cáº§n cÃ³ Ä‘Ã¡nh dáº¥u riÃªng vÃ­ dá»¥ Easy_QA, Medium_QA, Hard_QA, Easy_NER, Medium_SA, Hard_SA, v.v.\n",
    "- CÃ¡c cÃ¢u há»i cáº§n Ä‘a dáº¡ng vá» chá»§ Ä‘á» vÃ  Ä‘á»™ khÃ³, khÃ´ng láº·p láº¡i nhiá»u.\n",
    "4. YÃªu cáº§u khÃ¡c\n",
    "- ÄÃ¡nh dáº¥u rÃµ:\n",
    "    + Section (VD: \"Báº£ng cÃ¢n Ä‘á»‘i káº¿ toÃ¡n\", \"Thuyáº¿t minh\", \"CÃ´ng bá»‘ thÃ´ng tin\").\n",
    "    + Loáº¡i ná»™i dung: báº£ng, text, hoáº·c cáº£ hai.\n",
    "    + Náº¿u bÃ¡o cÃ¡o hoáº·c Ä‘oáº¡n thÃ´ng tin lÃ  tiáº¿ng Anh â†’ dá»‹ch sang tiáº¿ng Viá»‡t theo phong cÃ¡ch cá»§a bÃ¡o cÃ¡o tÃ i chÃ­nh.\n",
    "- Vá»›i bÃ¡o cÃ¡o ngáº¯n, khÃ´ng cÃ³ báº£ng (VD: bÃ¡o cÃ¡o há»£p nháº¥t) â†’ váº«n Ã¡p dá»¥ng quy táº¯c trÃªn, chá»‰ Ä‘iá»u chá»‰nh cÃ¢u há»i cho phÃ¹ há»£p.\n",
    "\n",
    "5. Output JSON máº«u\n",
    "[\n",
    "    {\n",
    "    \"chunk_id\": \"1\",\n",
    "    \"content\": \"CÃ´ng ty: CÃ´ng ty Cá»• pháº§n Thá»±c pháº©m LÃ¢m Äá»“ng\\nMÃ£ cá»• phiáº¿u: KhÃ´ng cÃ³\\nLoáº¡i bÃ¡o cÃ¡o: BÃ¡o cÃ¡o tÃ i chÃ­nh riÃªng quÃ½ II/2024\\nThá»i gian: PhÃ¡t hÃ nh thÃ¡ng 10/2024, QuÃ½ II/2024\\nÃ kiáº¿n kiá»ƒm toÃ¡n: KhÃ´ng cÃ³\\n\\nSection: Báº£ng cÃ¢n Ä‘á»‘i káº¿ toÃ¡n (Pháº§n A - TÃ i sáº£n ngáº¯n háº¡n)\\nLoáº¡i ná»™i dung: Báº£ng\\n| Chá»‰ tiÃªu | MÃ£ sá»‘ | Thuyáº¿t minh | Sá»‘ cuá»‘i quÃ½ | Sá»‘ Ä‘áº§u nÄƒm |\\n|----------|--------|-------------|-------------|------------|\\n| A. TÃ€I Sáº¢N NGáº®N Háº N | 100 | | 129.431.969.001 | 127.524.284.310 |\\n| I. Tiá»n vÃ  cÃ¡c khoáº£n tÆ°Æ¡ng Ä‘Æ°Æ¡ng tiá»n | 110 | | 16.831.267.495 | 17.384.196.156 |\\n| 1. Tiá»n | 111 | | 3.780.407.221 | 12.384.196.156 |\\n| 2. CÃ¡c khoáº£n tÆ°Æ¡ng Ä‘Æ°Æ¡ng tiá»n | 112 | | 13.050.860.274 | 5.000.000.000 |\\n| II. CÃ¡c khoáº£n Ä‘áº§u tÆ° tÃ i chÃ­nh ngáº¯n háº¡n | 120 | | 42.000.000.000 | 60.000.000.000 |\\n| 1. Chá»©ng khoÃ¡n kinh doanh | 121 | | - | - |\\n| 2. Dá»± phÃ²ng giáº£m giÃ¡ chá»©ng khoÃ¡n kinh doanh | 122 | | - | - |\\n| 3. Äáº§u tÆ° náº¯m giá»¯ Ä‘áº¿n ngÃ y Ä‘Ã¡o háº¡n | 123 | | 42.000.000.000 | 60.000.000.000 |\\n| III. CÃ¡c khoáº£n pháº£i thu ngáº¯n háº¡n | 130 | | 2.481.490.083 | 7.121.118.051 |\\n| 1. Pháº£i thu ngáº¯n háº¡n cá»§a khÃ¡ch hÃ ng | 131 | | 1.217.081.219 | 4.151.614.789 |\\n| 2. Tráº£ trÆ°á»›c cho ngÆ°á»i bÃ¡n ngáº¯n háº¡n | 132 | | 1.159.680.597 | 252.269.403 |\\n| 3. Pháº£i thu ná»™i bá»™ ngáº¯n háº¡n | 133 | | - | - |\\n| 4. Pháº£i thu theo tiáº¿n Ä‘á»™ káº¿ hoáº¡ch há»£p Ä‘á»“ng xÃ¢y dá»±ng | 134 | | - | - |\\n| 5. Pháº£i thu vá» cho vay ngáº¯n háº¡n | 135 | | - | - |\\n| 6. Pháº£i thu ngáº¯n háº¡n khÃ¡c | 136 | | 104.728.267 | 17.952.907.545 |\\n| 7. Dá»± phÃ²ng pháº£i thu ngáº¯n háº¡n khÃ³ Ä‘Ã²i | 137 | | - | (15.235.673.686) |\\n| IV. HÃ ng tá»“n kho | 140 | | 67.069.015.034 | 41.395.556.696 |\\n| 1. HÃ ng tá»“n kho | 141 | | 67.069.015.034 | 41.395.556.696 |\\n| 2. Dá»± phÃ²ng giáº£m giÃ¡ hÃ ng tá»“n kho | 149 | | - | - |\\n| V. TÃ i sáº£n ngáº¯n háº¡n khÃ¡c | 150 | | 1.050.196.389 | 1.623.413.407 |\\n| 1. Chi phÃ­ tráº£ trÆ°á»›c ngáº¯n háº¡n | 151 | | 498.882.665 | 1.183.019.212 |\\n| 2. Thuáº¿ GTGT Ä‘Æ°á»£c kháº¥u trá»« | 152 | | - | - |\\n| 3. Thuáº¿ vÃ  cÃ¡c khoáº£n khÃ¡c pháº£i thu NhÃ  nÆ°á»›c | 153 | | 440.394.195 | 440.394.195 |\\n| 4. Giao dá»‹ch mua bÃ¡n láº¡i trÃ¡i phiáº¿u ChÃ­nh phá»§ | 154 | | - | - |\\n| 5. TÃ i sáº£n ngáº¯n háº¡n khÃ¡c | 155 | | 110.919.529 | - |\",\n",
    "    \"questions\": [\n",
    "        {\"question\": \"Tá»•ng tÃ i sáº£n ngáº¯n háº¡n cuá»‘i quÃ½ II/2024 lÃ  bao nhiÃªu?\", \"difficulty\": \"Easy_QA\"},\n",
    "        {\"question\": \"HÃ ng tá»“n kho cuá»‘i quÃ½ lÃ  bao nhiÃªu VND?\", \"difficulty\": \"Easy_QA\"},\n",
    "        {\"question\": \"So sÃ¡nh tiá»n vÃ  tÆ°Æ¡ng Ä‘Æ°Æ¡ng tiá»n cuá»‘i quÃ½ vá»›i Ä‘áº§u nÄƒm, thay Ä‘á»•i nhÆ° tháº¿ nÃ o?\", \"difficulty\": \"Medium_QA\"},\n",
    "        {\"question\": \"Tá»· lá»‡ Ä‘áº§u tÆ° tÃ i chÃ­nh ngáº¯n háº¡n trÃªn tá»•ng tÃ i sáº£n ngáº¯n háº¡n lÃ  bao nhiÃªu pháº§n trÄƒm?\", \"difficulty\": \"Medium_QA\"},\n",
    "        {\"question\": \"ÄÃ¡nh giÃ¡ kháº£ nÄƒng thanh khoáº£n dá»±a trÃªn tá»· trá»ng tiá»n vÃ  tÆ°Æ¡ng Ä‘Æ°Æ¡ng tiá»n trong tÃ i sáº£n ngáº¯n háº¡n.\", \"difficulty\": \"Medium_SA\"},\n",
    "        {\"question\": \"TÃ­nh há»‡ sá»‘ thanh toÃ¡n nhanh (Quick Ratio) dá»±a trÃªn tÃ i sáº£n ngáº¯n háº¡n vÃ  ná»£ ngáº¯n háº¡n tá»« báº£ng cÃ¢n Ä‘á»‘i.\", \"difficulty\": \"Hard_QA\"},\n",
    "        {\"question\": \"PhÃ¢n tÃ­ch rá»§i ro tÃ i chÃ­nh náº¿u hÃ ng tá»“n kho tiáº¿p tá»¥c tÄƒng máº¡nh trong quÃ½ tá»›i.\", \"difficulty\": \"Hard_SA\"},\n",
    "        {\"question\": \"Dá»± bÃ¡o tÃ¡c Ä‘á»™ng cá»§a viá»‡c giáº£m cÃ¡c khoáº£n pháº£i thu ngáº¯n háº¡n Ä‘áº¿n thanh khoáº£n cÃ´ng ty.\", \"difficulty\": \"Hard_SA\"}\n",
    "    ]\n",
    "    },\n",
    "    {\n",
    "        \"chunk_id\": \"2\",\n",
    "        \"content\": \"CÃ´ng ty: CÃ´ng ty Cá»• pháº§n Thá»±c pháº©m LÃ¢m Äá»“ng\\nMÃ£ cá»• phiáº¿u: KhÃ´ng cÃ³\\nLoáº¡i bÃ¡o cÃ¡o: BÃ¡o cÃ¡o tÃ i chÃ­nh riÃªng quÃ½ II/2024\\nThá»i gian: PhÃ¡t hÃ nh thÃ¡ng 10/2024, QuÃ½ II/2024\\nÃ kiáº¿n kiá»ƒm toÃ¡n: KhÃ´ng cÃ³\\n\\nSection: Báº£ng cÃ¢n Ä‘á»‘i káº¿ toÃ¡n (Pháº§n B - TÃ i sáº£n dÃ i háº¡n)\\nLoáº¡i ná»™i dung: Báº£ng\\n| Chá»‰ tiÃªu | MÃ£ sá»‘ | Thuyáº¿t minh | Sá»‘ cuá»‘i quÃ½ | Sá»‘ Ä‘áº§u nÄƒm |\\n|----------|--------|-------------|-------------|------------|\\n| B. TÃ€I Sáº¢N DÃ€I Háº N | 200 | | 46.786.914.057 | 48.539.257.373 |\\n| I. CÃ¡c khoáº£n pháº£i thu dÃ i háº¡n | 210 | | - | - |\\n| 1. Pháº£i thu dÃ i háº¡n cá»§a khÃ¡ch hÃ ng | 211 | | - | - |\\n| 2. Tráº£ trÆ°á»›c cho ngÆ°á»i bÃ¡n dÃ i háº¡n | 212 | | - | - |\\n| 3. Vá»‘n kinh doanh á»Ÿ Ä‘Æ¡n vá»‹ trá»±c thuá»™c | 213 | | - | - |\\n| 4. Pháº£i thu ná»™i bá»™ dÃ i háº¡n | 214 | | - | - |\\n| 5. Pháº£i thu vá» cho vay dÃ i háº¡n | 215 | | - | - |\\n| 6. Pháº£i thu dÃ i háº¡n khÃ¡c | 216 | | - | - |\\n| II. TÃ i sáº£n cá»‘ Ä‘á»‹nh | 220 | | 42.731.112.649 | 43.969.139.154 |\\n| 1. TÃ i sáº£n cá»‘ Ä‘á»‹nh há»¯u hÃ¬nh | 221 | | 42.731.112.649 | 43.969.139.154 |\\n| - NguyÃªn giÃ¡ | 222 | | 136.584.468.433 | 120.670.272.525 |\\n| - GiÃ¡ trá»‹ hao mÃ²n lÅ©y káº¿ | 223 | | (93.853.355.784) | (76.701.133.371) |\\n| 2. TÃ i sáº£n cá»‘ Ä‘á»‹nh thuÃª tÃ i chÃ­nh | 224 | | - | - |\\n| 3. TÃ i sáº£n cá»‘ Ä‘á»‹nh vÃ´ hÃ¬nh | 227 | | - | - |\\n| - NguyÃªn giÃ¡ | 228 | | 314.162.500 | 314.162.500 |\\n| - GiÃ¡ trá»‹ hao mÃ²n lÅ©y káº¿ | 229 | | (314.162.500) | (314.162.500) |\\n| III. Báº¥t Ä‘á»™ng sáº£n Ä‘áº§u tÆ° | 230 | | - | - |\\n| - NguyÃªn giÃ¡ | 231 | | - | - |\\n| - GiÃ¡ trá»‹ hao mÃ²n lÅ©y káº¿ | 232 | | - | - |\\n| IV. TÃ i sáº£n dá»Ÿ dang dÃ i háº¡n | 240 | | - | - |\\n| 1. Chi phÃ­ sáº£n xuáº¥t, kinh doanh dá»Ÿ dang dÃ i háº¡n | 241 | | - | - |\\n| V. Äáº§u tÆ° tÃ i chÃ­nh dÃ i háº¡n | 250 | | - | - |\\n| 1. Äáº§u tÆ° vÃ o cÃ´ng ty con | 251 | | - | 15.000.000.000 |\\n| 2. Äáº§u tÆ° vÃ o cÃ´ng ty liÃªn káº¿t, liÃªn doanh | 252 | | - | - |\\n| 3. Äáº§u tÆ° gÃ³p vá»‘n vÃ o Ä‘Æ¡n vá»‹ khÃ¡c | 253 | | - | - |\\n| 4. Dá»± phÃ²ng Ä‘áº§u tÆ° tÃ i chÃ­nh dÃ i háº¡n | 254 | | - | (15.000.000.000) |\\n| 5. Äáº§u tÆ° náº¯m giá»¯ Ä‘áº¿n ngÃ y Ä‘Ã¡o háº¡n | 255 | | - | - |\\n| VI. TÃ i sáº£n dÃ i háº¡n khÃ¡c | 260 | | 4.055.801.408 | 4.570.118.219 |\\n| 1. Chi phÃ­ tráº£ trÆ°á»›c dÃ i háº¡n | 261 | | 4.055.801.408 | 4.570.118.219 |\\n| 2. TÃ i sáº£n thuáº¿ thu nháº­p hoÃ£n láº¡i | 262 | | - | - |\\n| 3. Thiáº¿t bá»‹, váº­t tÆ°, phá»¥ tÃ¹ng thay tháº¿ dÃ i háº¡n | 263 | | - | - |\\n| 4. TÃ i sáº£n dÃ i háº¡n khÃ¡c | 268 | | - | - |\\n| Tá»”NG Cá»˜NG TÃ€I Sáº¢N | 270 | | 176.218.883.058 | 176.063.541.683 |\",\n",
    "        \"questions\": [\n",
    "            {\"question\": \"Tá»•ng tÃ i sáº£n dÃ i háº¡n cuá»‘i quÃ½ II/2024 lÃ  bao nhiÃªu?\", \"difficulty\": \"Easy_QA\"},\n",
    "            {\"question\": \"GiÃ¡ trá»‹ tÃ i sáº£n cá»‘ Ä‘á»‹nh há»¯u hÃ¬nh cuá»‘i quÃ½ lÃ  bao nhiÃªu VND?\", \"difficulty\": \"Easy_QA\"},\n",
    "            {\"question\": \"So sÃ¡nh chi phÃ­ tráº£ trÆ°á»›c dÃ i háº¡n cuá»‘i quÃ½ vá»›i Ä‘áº§u nÄƒm.\", \"difficulty\": \"Medium_QA\"},\n",
    "            {\"question\": \"Tá»· lá»‡ tÃ i sáº£n cá»‘ Ä‘á»‹nh trÃªn tá»•ng tÃ i sáº£n dÃ i háº¡n lÃ  bao nhiÃªu pháº§n trÄƒm?\", \"difficulty\": \"Medium_QA\"},\n",
    "            {\"question\": \"ÄÃ¡nh giÃ¡ sá»± phá»¥ thuá»™c vÃ o tÃ i sáº£n cá»‘ Ä‘á»‹nh trong cÆ¡ cáº¥u tÃ i sáº£n dÃ i háº¡n.\", \"difficulty\": \"Medium_SA\"},\n",
    "            {\"question\": \"PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng cá»§a viá»‡c khÃ´ng cÃ³ Ä‘áº§u tÆ° tÃ i chÃ­nh dÃ i háº¡n Ä‘áº¿n chiáº¿n lÆ°á»£c tÄƒng trÆ°á»Ÿng.\", \"difficulty\": \"Hard_SA\"},\n",
    "            {\"question\": \"Dá»± bÃ¡o rá»§i ro náº¿u giÃ¡ trá»‹ hao mÃ²n tÃ i sáº£n cá»‘ Ä‘á»‹nh tiáº¿p tá»¥c tÄƒng nhanh.\", \"difficulty\": \"Hard_SA\"},\n",
    "            {\"question\": \"ÄÃ¡nh giÃ¡ hiá»‡u quáº£ sá»­ dá»¥ng tÃ i sáº£n dÃ i háº¡n dá»±a trÃªn cÆ¡ cáº¥u hiá»‡n táº¡i.\", \"difficulty\": \"Hard_SA\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"chunk_id\": \"3\",\n",
    "        \"content\": \"CÃ´ng ty: CÃ´ng ty Cá»• pháº§n Thá»±c pháº©m LÃ¢m Äá»“ng\\nMÃ£ cá»• phiáº¿u: KhÃ´ng cÃ³\\nLoáº¡i bÃ¡o cÃ¡o: BÃ¡o cÃ¡o tÃ i chÃ­nh riÃªng quÃ½ II/2024\\nThá»i gian: PhÃ¡t hÃ nh thÃ¡ng 10/2024, QuÃ½ II/2024\\nÃ kiáº¿n kiá»ƒm toÃ¡n: KhÃ´ng cÃ³\\n\\nSection: Báº£ng cÃ¢n Ä‘á»‘i káº¿ toÃ¡n (Pháº§n C - Ná»£ pháº£i tráº£ vÃ  Pháº§n D - Vá»‘n chá»§ sá»Ÿ há»¯u)\\nLoáº¡i ná»™i dung: Báº£ng\\n| Chá»‰ tiÃªu | MÃ£ sá»‘ | Thuyáº¿t minh | Sá»‘ cuá»‘i quÃ½ | Sá»‘ Ä‘áº§u nÄƒm |\\n|----------|--------|-------------|-------------|------------|\\n| C. Ná»¢ PHáº¢I TRA | 300 | | 6.694.694.333 | 4.648.015.400 |\\n| I. Ná»£ ngáº¯n háº¡n | 310 | | 6.694.694.333 | 4.648.015.400 |\\n| 1. Pháº£i tráº£ ngÆ°á»i bÃ¡n ngáº¯n háº¡n | 311 | | 4.773.503.501 | 1.420.930.321 |\\n| 2. NgÆ°á»i mua tráº£ tiá»n trÆ°á»›c ngáº¯n háº¡n | 312 | | 208.000 | 180.000 |\\n| 3. Thuáº¿ vÃ  cÃ¡c khoáº£n pháº£i ná»™p nhÃ  nÆ°á»›c | 313 | | 716.626.406 | 1.979.632.282 |\\n| 4. Pháº£i tráº£ ngÆ°á»i lao Ä‘á»™ng | 314 | | 899.082.033 | 942.897.424 |\\n| 5. Chi phÃ­ pháº£i tráº£ ngáº¯n háº¡n | 315 | | - | - |\\n| 6. Pháº£i tráº£ ná»™i bá»™ ngáº¯n háº¡n | 316 | | - | - |\\n| 7. Pháº£i tráº£ theo tiáº¿n Ä‘á»™ káº¿ hoáº¡ch há»£p Ä‘á»“ng xÃ¢y dá»±ng | 317 | | - | - |\\n| 8. Doanh thu chÆ°a thá»±c hiá»‡n ngáº¯n háº¡n | 318 | | - | - |\\n| 9. Pháº£i tráº£ ngáº¯n háº¡n khÃ¡c | 319 | | 169.430.425 | 105.031.405 |\\n| 10. Vay vÃ  ná»£ thuÃª tÃ i chÃ­nh ngáº¯n háº¡n | 320 | | - | - |\\n| 11. Dá»± phÃ²ng pháº£i tráº£ ngáº¯n háº¡n | 321 | | - | - |\\n| 12. Quá»¹ khen thÆ°á»Ÿng, phÃºc lá»£i | 322 | | 135.843.968 | 199.343.968 |\\n| II. Ná»£ dÃ i háº¡n | 330 | | - | - |\\n| 1. Pháº£i tráº£ ngÆ°á»i bÃ¡n dÃ i háº¡n | 331 | | - | - |\\n| 2. NgÆ°á»i mua tráº£ tiá»n trÆ°á»›c dÃ i háº¡n | 332 | | - | - |\\n| 3. Chi phÃ­ pháº£i tráº£ dÃ i háº¡n | 333 | | - | - |\\n| 4. Pháº£i tráº£ ná»™i bá»™ vá» vá»‘n kinh doanh | 334 | | - | - |\\n| 5. Pháº£i tráº£ ná»™i bá»™ dÃ i háº¡n | 335 | | - | - |\\n| 6. Doanh thu chÆ°a thá»±c hiá»‡n dÃ i háº¡n | 336 | | - | - |\\n| 7. Pháº£i tráº£ dÃ i háº¡n khÃ¡c | 337 | | - | - |\\n| 8. Vay vÃ  ná»£ thuÃª tÃ i chÃ­nh dÃ i háº¡n | 338 | | - | - |\\n| D. Vá»N CHá»¦ Sá» Há»®U | 400 | | 169.524.188.725 | 171.415.526.283 |\\n| I. Vá»‘n chá»§ sá»Ÿ há»¯u | 410 | | 169.524.188.725 | 171.415.526.283 |\\n| 1. Vá»‘n Ä‘áº§u tÆ° cá»§a chá»§ sá»Ÿ há»¯u | 411 | | 146.571.500.000 | 146.571.500.000 |\\n| - Cá»• phiáº¿u phá»• thÃ´ng cÃ³ quyá»n biá»ƒu quyáº¿t | 411a | | 146.571.500.000 | 146.571.500.000 |\\n| - Cá»• phiáº¿u Æ°u Ä‘Ã£i | 411b | | - | - |\\n| 8. Quá»¹ Ä‘áº§u tÆ° phÃ¡t triá»ƒn | 418 | | - | 9.933.986.561 |\\n| 9. Quá»¹ há»— trá»£ sáº¯p xáº¿p doanh nghiá»‡p | 419 | | - | - |\\n| 10. Quá»¹ khÃ¡c thuá»™c vá»‘n chá»§ sá»Ÿ há»¯u | 420 | | - | - |\\n| 11. Lá»£i nhuáº­n sau thuáº¿ chÆ°a phÃ¢n phá»‘i | 421 | | 22.952.688.725 | 14.910.039.722 |\\n| - LNST chÆ°a phÃ¢n phá»‘i lÅ©y káº¿ Ä‘áº¿n cuá»‘i ká»³ trÆ°á»›c | 421a | | 24.844.026.283 | 36.437.036.716 |\\n| - LNST chÆ°a phÃ¢n phá»‘i ká»³ nÃ y | 421b | | (1.891.337.558) | (21.526.996.994) |\\n| II. Nguá»“n kinh phÃ­ vÃ  quá»¹ khÃ¡c | 430 | | - | - |\\n| Tá»”NG Cá»˜NG NGUá»’N Vá»N | 440 | | 176.218.883.058 | 176.063.541.683 |\",\n",
    "        \"questions\": [\n",
    "            {\"question\": \"Ná»£ pháº£i tráº£ cuá»‘i quÃ½ II/2024 lÃ  bao nhiÃªu?\", \"difficulty\": \"Easy_QA\"},\n",
    "            {\"question\": \"Vá»‘n chá»§ sá»Ÿ há»¯u cuá»‘i quÃ½ lÃ  bao nhiÃªu VND?\", \"difficulty\": \"Easy_QA\"},\n",
    "            {\"question\": \"Tá»· lá»‡ ná»£ pháº£i tráº£ trÃªn tá»•ng nguá»“n vá»‘n cuá»‘i quÃ½ lÃ  bao nhiÃªu?\", \"difficulty\": \"Medium_QA\"},\n",
    "            {\"question\": \"So sÃ¡nh pháº£i tráº£ ngÆ°á»i bÃ¡n ngáº¯n háº¡n cuá»‘i quÃ½ vá»›i Ä‘áº§u nÄƒm.\", \"difficulty\": \"Medium_QA\"},\n",
    "            {\"question\": \"ÄÃ¡nh giÃ¡ cÆ¡ cáº¥u ná»£ ngáº¯n háº¡n cÃ³ an toÃ n cho cÃ´ng ty khÃ´ng?\", \"difficulty\": \"Medium_SA\"},\n",
    "            {\"question\": \"TÃ­nh há»‡ sá»‘ ná»£ trÃªn vá»‘n chá»§ sá»Ÿ há»¯u (D/E ratio) cuá»‘i quÃ½.\", \"difficulty\": \"Hard_QA\"},\n",
    "            {\"question\": \"PhÃ¢n tÃ­ch rá»§i ro Ä‘áº§u tÆ° náº¿u lá»£i nhuáº­n sau thuáº¿ Ã¢m.\", \"difficulty\": \"Hard_SA\"},\n",
    "            {\"question\": \"ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ phá»¥ thuá»™c vÃ o vá»‘n chá»§ sá»Ÿ há»¯u so vá»›i ná»£.\", \"difficulty\": \"Hard_SA\"}\n",
    "        ]\n",
    "    }\n",
    "DÆ°á»›i Ä‘Ã¢y lÃ  bÃ¡o cÃ¡o Ä‘Ã£ Ä‘Æ°á»£c trÃ­ch xuáº¥t báº±ng pdfplumber:\n",
    "\"\"\"\n",
    "\n",
    "# Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(EXTRACTED_TXT_FOLDER, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Ghi log ---\n",
    "def log_error(filename, api_key, error_message):\n",
    "    log_path = ERROR_LOG\n",
    "    log_entry = {\n",
    "        \"file\": filename,\n",
    "        \"api_key\": api_key,\n",
    "        \"error\": error_message,\n",
    "        \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    }\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(log_entry, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"ğŸ›‘ ÄÃ£ ghi log lá»—i cho {filename}\")\n",
    "\n",
    "\n",
    "def log_incomplete(filename, partial_content):\n",
    "    log_path = INCOMPLETE_LOG\n",
    "    log_entry = {\n",
    "        \"file\": filename,\n",
    "        \"status\": \"incomplete\",\n",
    "        \"length\": len(partial_content),\n",
    "        \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    }\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(log_entry, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"ğŸ“Œ ÄÃ£ ghi log incomplete cho {filename}\")\n",
    "\n",
    "\n",
    "# Äá»c ná»™i dung tá»« file .txt Ä‘Ã£ trÃ­ch xuáº¥t\n",
    "def read_text_from_txt(txt_path: Path):\n",
    "    try:\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read().strip()\n",
    "        # Chuáº©n hÃ³a text: loáº¡i bá» kÃ½ tá»± láº¡\n",
    "        text = re.sub(r'[^\\w\\s.,|]', '', text)\n",
    "        print(f\"ğŸ“„ ÄÃ£ Ä‘á»c text tá»«: {txt_path}\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i Ä‘á»c file {txt_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Gá»­i prompt lÃªn Gemini báº±ng API key cá»¥ thá»ƒ\n",
    "def ask_gemini_from_text(pdf_text, instruction, api_key):\n",
    "    full_prompt = f\"\"\"{instruction}\n",
    "------------------------------\n",
    "- BÃ¡o cÃ¡o tÃ i chÃ­nh: {pdf_text}\n",
    "\"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Lá»—i gá»i Gemini API (key {api_key[:8]}...): {e}\"\n",
    "\n",
    "\n",
    "# LÆ°u káº¿t quáº£, phÃ¢n loáº¡i theo cÃ¡c trÆ°á»ng há»£p\n",
    "def save_output(filename, content):\n",
    "    json_path = os.path.join(OUTPUT_FOLDER, filename.replace(\".txt\", \".json\"))\n",
    "\n",
    "    if not content:\n",
    "        print(f\"âš ï¸ KhÃ´ng cÃ³ ná»™i dung Ä‘á»ƒ lÆ°u cho {filename}\")\n",
    "        return False\n",
    "\n",
    "    # TrÆ°á»ng há»£p lá»—i âŒ\n",
    "    if \"âŒ\" in content:\n",
    "        log_error(filename, \"unknown\", content)\n",
    "        return False\n",
    "\n",
    "    # TrÆ°á»ng há»£p cÃ³ block ```json ... ```\n",
    "    if \"```json\" in content:\n",
    "        try:\n",
    "            extracted = re.search(r\"```json(.*?)```\", content, re.DOTALL)\n",
    "            if extracted:\n",
    "                clean_json = extracted.group(1).strip()\n",
    "                data = json.loads(clean_json)\n",
    "                with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "                print(f\"âœ… LÆ°u JSON thÃ nh cÃ´ng (chuáº©n format): {json_path}\")\n",
    "                return True\n",
    "            else:\n",
    "                # CÃ³ ```json nhÆ°ng khÃ´ng cÃ³ dáº¥u káº¿t thÃºc ```\n",
    "                incomplete_part = content.split(\"```json\", 1)[-1].strip()\n",
    "                with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(incomplete_part)\n",
    "                log_incomplete(filename, incomplete_part)\n",
    "                print(f\"âš ï¸ JSON bá»‹ ngáº¯t, Ä‘Ã£ lÆ°u pháº§n incomplete: {json_path}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Lá»—i parse JSON trong {filename}: {e}\")\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "            log_incomplete(filename, content)\n",
    "            return False\n",
    "\n",
    "    # TrÆ°á»ng há»£p khÃ´ng cÃ³ block ```json\n",
    "    else:\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"âœ… LÆ°u JSON thÃ nh cÃ´ng (dáº¡ng raw): {json_path}\")\n",
    "            return True\n",
    "        except json.JSONDecodeError:\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "            log_incomplete(filename, content)\n",
    "            print(f\"âš ï¸ Ná»™i dung khÃ´ng pháº£i JSON hoÃ n chá»‰nh, Ä‘Ã£ lÆ°u raw: {json_path}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# XÃ³a entry lá»—i trong error_log khi file xá»­ lÃ½ thÃ nh cÃ´ng\n",
    "def remove_error_log_entry(filename):\n",
    "    log_path = ERROR_LOG\n",
    "    if not Path(log_path).exists():\n",
    "        return\n",
    "    new_lines = []\n",
    "    removed = False\n",
    "    with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "                if entry[\"file\"] == filename:\n",
    "                    removed = True\n",
    "                    continue\n",
    "                new_lines.append(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "    if removed:\n",
    "        with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(new_lines) + (\"\\n\" if new_lines else \"\"))\n",
    "        print(f\"ğŸ§¹ ÄÃ£ xÃ³a log lá»—i cÅ© cho {filename}\")\n",
    "\n",
    "\n",
    "# XÃ³a entry incomplete trong incomplete_log khi file xá»­ lÃ½ thÃ nh cÃ´ng (thÃªm má»›i)\n",
    "def remove_incomplete_log_entry(filename):\n",
    "    log_path = INCOMPLETE_LOG\n",
    "    if not Path(log_path).exists():\n",
    "        return\n",
    "    new_lines = []\n",
    "    removed = False\n",
    "    with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "                if entry[\"file\"] == filename:\n",
    "                    removed = True\n",
    "                    continue\n",
    "                new_lines.append(line.strip())\n",
    "            except:\n",
    "                continue\n",
    "    if removed:\n",
    "        with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(new_lines) + (\"\\n\" if new_lines else \"\"))\n",
    "        print(f\"ğŸ§¹ ÄÃ£ xÃ³a log incomplete cÅ© cho {filename}\")\n",
    "\n",
    "\n",
    "# Xá»­ lÃ½ má»™t file .txt vá»›i nhÃ³m API key riÃªng\n",
    "def process_txt_file(txt_file: Path, api_keys: cycle):\n",
    "    print(f\"\\nğŸ“ Äang xá»­ lÃ½: {txt_file.name}\")\n",
    "\n",
    "    text = read_text_from_txt(txt_file)\n",
    "    if not text:\n",
    "        return\n",
    "\n",
    "    api_key = next(api_keys)\n",
    "    result = ask_gemini_from_text(text, INSTRUCTION, api_key)\n",
    "\n",
    "    success = save_output(txt_file.name, result)\n",
    "    if success:\n",
    "        remove_error_log_entry(txt_file.name)\n",
    "        remove_incomplete_log_entry(txt_file.name)\n",
    "\n",
    "\n",
    "# GÃ¡n file .txt cho tá»«ng luá»“ng theo round-robin\n",
    "def assign_txts_to_threads(txt_files, num_threads):\n",
    "    assigned = [[] for _ in range(num_threads)]\n",
    "    for idx, txt in enumerate(txt_files):\n",
    "        assigned[idx % num_threads].append(txt)\n",
    "    return assigned\n",
    "\n",
    "\n",
    "# Xá»­ lÃ½ song song nhiá»u file .txt\n",
    "def process_all_txts_concurrently(max_workers=NUM_THREADS):\n",
    "    txt_files = list(Path(EXTRACTED_TXT_FOLDER).glob(\"*.txt\"))\n",
    "    if not txt_files:\n",
    "        print(f\"ğŸ“‚ KhÃ´ng cÃ³ file .txt nÃ o trong thÆ° má»¥c {EXTRACTED_TXT_FOLDER} .\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸš€ Tá»•ng sá»‘ file cáº§n xá»­ lÃ½: {len(txt_files)}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Bá» qua nhá»¯ng file Ä‘Ã£ xá»­ lÃ½ thÃ nh cÃ´ng (cÃ³ JSON há»£p lá»‡)\n",
    "    processed_files = {Path(f).stem for f in Path(OUTPUT_FOLDER).glob(\"*.json\")}\n",
    "\n",
    "    # Láº¥y danh sÃ¡ch file lá»—i tá»« log\n",
    "    error_files = set()\n",
    "    if Path(ERROR_LOG).exists():\n",
    "        with open(ERROR_LOG, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    entry = json.loads(line)\n",
    "                    error_files.add(Path(entry[\"file\"]).stem)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    # Láº¥y danh sÃ¡ch file incomplete tá»« log\n",
    "    incomplete_files = set()\n",
    "    if Path(INCOMPLETE_LOG).exists():\n",
    "        with open(INCOMPLETE_LOG, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    entry = json.loads(line)\n",
    "                    incomplete_files.add(Path(entry[\"file\"]).stem)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    # Xá»­ lÃ½ nhá»¯ng file chÆ°a cÃ³ JSON hoáº·c bá»‹ lá»—i hoáº·c incomplete\n",
    "    files_to_process = [\n",
    "        txt for txt in txt_files\n",
    "        if txt.stem not in processed_files or txt.stem in error_files or txt.stem in incomplete_files\n",
    "    ]\n",
    "\n",
    "    print(f\"ğŸ“Œ Sáº½ xá»­ lÃ½ {len(files_to_process)} file (bao gá»“m lá»—i, incomplete & chÆ°a cÃ³).\")\n",
    "\n",
    "    # GÃ¡n file cho tá»«ng thread\n",
    "    thread_txt_lists = assign_txts_to_threads(files_to_process, max_workers)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for i in range(max_workers):\n",
    "            txt_list = thread_txt_lists[i]\n",
    "            api_keys_cycle = cycle(api_key_groups[i])\n",
    "            for txt in txt_list:\n",
    "                futures.append(executor.submit(process_txt_file, txt, api_keys_cycle))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            _ = future.result()\n",
    "\n",
    "    print(f\"\\nâ±ï¸ Xong! Tá»•ng thá»i gian: {time.time() - start_time:.2f} giÃ¢y\")\n",
    "\n",
    "\n",
    "# ğŸ§ª Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_txts_concurrently(max_workers=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc396f2b",
   "metadata": {},
   "source": [
    "### Kiá»ƒm tra cÃ¡c file há»ng vÃ  file chÆ°a tá»“n táº¡i, há»i ngÆ°á»i dÃ¹ng cÃ³ chuyá»ƒn file há»ng vÃ  chá»‰ giá»¯ cÃ¡c file tá»‘t á»Ÿ folder chÃ­nh hay khÃ´ng.So sÃ¡nh tá»« txt_folder, folder output vÃ  chuyá»ƒn cÃ¡c file lá»—i(xÃ³a file lá»—i trong file output) sang folder continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86273b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Káº¿t quáº£ so sÃ¡nh:\n",
      "- Tá»•ng sá»‘ file .txt: 6\n",
      "- Tá»•ng sá»‘ file .json: 4\n",
      "- Sá»‘ file chÆ°a cÃ³ .json: 2\n",
      "- Sá»‘ file JSON há»£p lá»‡ (good): 4\n",
      "- Sá»‘ file bá»‹ ngáº¯t Ä‘oáº¡n (incomplete): 0\n",
      "\n",
      "âš ï¸ Danh sÃ¡ch file chÆ°a cÃ³ .json:\n",
      "  - 000000014459603_EN_FinacialStatemants_Q4_2024.Holding_Company.txt  (dá»± kiáº¿n sáº½ cÃ³ 000000014459603_EN_FinacialStatemants_Q4_2024.Holding_Company.json trong folder_2.5_step1)\n",
      "  - 000000014459629_EN_FinacialStatements_Q4_2024_Final.signed.txt  (dá»± kiáº¿n sáº½ cÃ³ 000000014459629_EN_FinacialStatements_Q4_2024_Final.signed.json trong folder_2.5_step1)\n",
      "\n",
      "âœ… Danh sÃ¡ch file JSON há»£p lá»‡:\n",
      "  - 000000014459170_EN__SeparateFinancialStatements_Q4_2024.json\n",
      "  - 000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json\n",
      "  - 000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json\n",
      "  - 000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json\n",
      "ğŸ“‚ ÄÃ£ copy JSON há»£p lá»‡ folder_2.5_step1\\000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json â†’ folder_2.5_step1_good\\000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json\n",
      "ğŸ“‚ ÄÃ£ copy JSON há»£p lá»‡ folder_2.5_step1\\000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json â†’ folder_2.5_step1_good\\000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json\n",
      "ğŸ“‚ ÄÃ£ copy JSON há»£p lá»‡ folder_2.5_step1\\000000014459170_EN__SeparateFinancialStatements_Q4_2024.json â†’ folder_2.5_step1_good\\000000014459170_EN__SeparateFinancialStatements_Q4_2024.json\n",
      "ğŸ“‚ ÄÃ£ copy JSON há»£p lá»‡ folder_2.5_step1\\000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json â†’ folder_2.5_step1_good\\000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json\n",
      "âœ… HoÃ n táº¥t copy 4 file JSON há»£p lá»‡.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ThÆ° má»¥c\n",
    "TXT_FOLDER = \"folder_2.5_txt\"\n",
    "OUTPUT_FOLDER = \"folder_2.5_step1\"\n",
    "CONTINUE_FOLDER = \"folder_2.5_step1_continue\"\n",
    "GOOD_FOLDER = \"folder_2.5_step1_good\"\n",
    "\n",
    "# Táº¡o cÃ¡c thÆ° má»¥c náº¿u chÆ°a cÃ³\n",
    "os.makedirs(CONTINUE_FOLDER, exist_ok=True)\n",
    "os.makedirs(GOOD_FOLDER, exist_ok=True)\n",
    "\n",
    "def is_json_complete(file_path: Path) -> bool:\n",
    "    \"\"\"Kiá»ƒm tra file json cÃ³ há»£p lá»‡ khÃ´ng\"\"\"\n",
    "    try:\n",
    "        text = file_path.read_text(encoding=\"utf-8\").strip()\n",
    "        if text.startswith(\"âŒ Lá»—i gá»i Gemini\"):\n",
    "            return False\n",
    "        if text.startswith(\"```json\"):\n",
    "            if text.endswith(\"```\"):\n",
    "                text = text.strip(\"`\").replace(\"json\", \"\", 1).strip()\n",
    "            else:\n",
    "                return False  # khÃ´ng Ä‘Ã³ng ``` => incomplete\n",
    "        json.loads(text)  # thá»­ parse\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def compare_folders():\n",
    "    txt_files = {Path(f).stem for f in Path(TXT_FOLDER).glob(\"*.txt\")}\n",
    "    json_files = {Path(f).stem for f in Path(OUTPUT_FOLDER).glob(\"*.json\")}\n",
    "\n",
    "    missing = txt_files - json_files\n",
    "    incomplete = set()\n",
    "    good = set()\n",
    "\n",
    "    for json_file in Path(OUTPUT_FOLDER).glob(\"*.json\"):\n",
    "        if is_json_complete(json_file):\n",
    "            good.add(json_file.stem)\n",
    "        else:\n",
    "            incomplete.add(json_file.stem)\n",
    "\n",
    "    print(\"ğŸ“Š Káº¿t quáº£ so sÃ¡nh:\")\n",
    "    print(f\"- Tá»•ng sá»‘ file .txt: {len(txt_files)}\")\n",
    "    print(f\"- Tá»•ng sá»‘ file .json: {len(json_files)}\")\n",
    "    print(f\"- Sá»‘ file chÆ°a cÃ³ .json: {len(missing)}\")\n",
    "    print(f\"- Sá»‘ file JSON há»£p lá»‡ (good): {len(good)}\")\n",
    "    print(f\"- Sá»‘ file bá»‹ ngáº¯t Ä‘oáº¡n (incomplete): {len(incomplete)}\")\n",
    "\n",
    "    if missing:\n",
    "        print(\"\\nâš ï¸ Danh sÃ¡ch file chÆ°a cÃ³ .json:\")\n",
    "        for fname in sorted(missing):\n",
    "            print(f\"  - {fname}.txt  (dá»± kiáº¿n sáº½ cÃ³ {fname}.json trong {OUTPUT_FOLDER})\")\n",
    "\n",
    "    if good:\n",
    "        print(\"\\nâœ… Danh sÃ¡ch file JSON há»£p lá»‡:\")\n",
    "        for fname in sorted(good):\n",
    "            print(f\"  - {fname}.json\")\n",
    "\n",
    "    if incomplete:\n",
    "        print(\"\\nâš ï¸ Danh sÃ¡ch file bá»‹ ngáº¯t Ä‘oáº¡n (incomplete):\")\n",
    "        for fname in sorted(incomplete):\n",
    "            print(f\"  - {fname}.json\")\n",
    "\n",
    "    return missing, incomplete, good\n",
    "\n",
    "def copy_incomplete_files(incomplete_files):\n",
    "    copied_count = 0\n",
    "    for fname in incomplete_files:\n",
    "        src = Path(OUTPUT_FOLDER) / f\"{fname}.json\"\n",
    "        dst = Path(CONTINUE_FOLDER) / f\"{fname}.json\"\n",
    "        if src.exists():\n",
    "            shutil.copy2(src, dst)\n",
    "            print(f\"ğŸ“‚ ÄÃ£ copy {src} â†’ {dst}\")\n",
    "            copied_count += 1\n",
    "    return copied_count\n",
    "\n",
    "def copy_good_files(good_files):\n",
    "    copied_count = 0\n",
    "    for fname in good_files:\n",
    "        src = Path(OUTPUT_FOLDER) / f\"{fname}.json\"\n",
    "        dst = Path(GOOD_FOLDER) / f\"{fname}.json\"\n",
    "        if src.exists():\n",
    "            shutil.copy2(src, dst)\n",
    "            print(f\"ğŸ“‚ ÄÃ£ copy JSON há»£p lá»‡ {src} â†’ {dst}\")\n",
    "            copied_count += 1\n",
    "    return copied_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    missing, incomplete, good = compare_folders()\n",
    "\n",
    "    if good:\n",
    "        # choice = input(f\"\\nâ“ CÃ³ muá»‘n copy {len(good)} file JSON há»£p lá»‡ sang {GOOD_FOLDER}? (y/n): \").strip().lower()\n",
    "        choice = \"y\"\n",
    "        if choice == \"y\":\n",
    "            copied_good = copy_good_files(good)\n",
    "            print(f\"âœ… HoÃ n táº¥t copy {copied_good} file JSON há»£p lá»‡.\")\n",
    "        else:\n",
    "            print(\"â© Bá» qua copy file JSON há»£p lá»‡.\")\n",
    "\n",
    "    if incomplete:\n",
    "        # choice = input(f\"\\nâ“ CÃ³ muá»‘n copy {len(incomplete)} file bá»‹ ngáº¯t Ä‘oáº¡n sang {CONTINUE_FOLDER}? (y/n): \").strip().lower()\n",
    "        choice = \"y\"\n",
    "        if choice == \"y\":\n",
    "            copied_incomplete = copy_incomplete_files(incomplete)\n",
    "            print(f\"âœ… HoÃ n táº¥t copy {copied_incomplete} file bá»‹ ngáº¯t.\")\n",
    "        else:\n",
    "            print(\"â© Bá» qua copy file bá»‹ ngáº¯t.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d84e04",
   "metadata": {},
   "source": [
    "## Sinh dá»¯ liá»‡u instruction data tá»« good_folder lá»c ra tá»« step1 tá»« bÆ°á»›c trÆ°á»›c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082f78a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tá»•ng sá»‘ API keys: 9\n",
      "Key 1: AIzaSyDurEPeaKYb1F9rCcF1rOY2-Et3VtPIJLg\n",
      "Key 2: AIzaSyDYjG9Z_fj4zttInrUm3wk7f7aKawpm3qE\n",
      "Key 3: AIzaSyDV9f9gyCt1-pbU-AX3HaYZrxMA417-Se4\n",
      "Key 4: AIzaSyDQClTO07TsamAs2vXuk_-s0EjX8GTEwvU\n",
      "Key 5: AIzaSyBO_S3_xvW4NmTU93Wsp9pnBVKNXe12O0A\n",
      "Key 6: AIzaSyAZnDLm3tcEfilmvdJVZCNMol_8ezR3Nj4\n",
      "Key 7: AIzaSyAt4K0VMxBmE80qWnyV_wAuSV5P5B4Rdq8\n",
      "Key 8: AIzaSyBk-Z6rGVq0bxqP_F_GgjFK1deMeqmVYco\n",
      "Key 9: AIzaSyBnjpOb7nJWOtQ_6m7031gm9vr8shIy-SQ\n",
      "9 API keys Ä‘Æ°á»£c tÃ¬m tháº¥y.\n",
      "ğŸš€ Tá»•ng sá»‘ file cáº§n xá»­ lÃ½: 4\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459170_EN__SeparateFinancialStatements_Q4_2024.json\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c content tá»«: 000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c content tá»«: 000000014459170_EN__SeparateFinancialStatements_Q4_2024.json\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c content tá»«: 000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json\n",
      "ğŸ“„ ÄÃ£ Ä‘á»c content tá»«: 000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json\n",
      "âœ… LÆ°u file thÃ nh cÃ´ng: folder_2.5_step2\\000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json\n",
      "âœ… LÆ°u file thÃ nh cÃ´ng: folder_2.5_step2\\000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json\n",
      "âœ… LÆ°u file thÃ nh cÃ´ng: folder_2.5_step2\\000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json\n",
      "âœ… LÆ°u file thÃ nh cÃ´ng: folder_2.5_step2\\000000014459170_EN__SeparateFinancialStatements_Q4_2024.json\n",
      "â±ï¸ Xong! Tá»•ng thá»i gian: 849.90 giÃ¢y\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from itertools import cycle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import threading\n",
    "\n",
    "# Táº£i biáº¿n mÃ´i trÆ°á»ng tá»« .env\n",
    "load_dotenv()\n",
    "\n",
    "# Láº¥y API keys tá»« .env vÃ  tÃ¡ch thÃ nh list\n",
    "API_KEYS = os.getenv(\"API_KEYS\", \"\").replace('\"', '').split(\",\")\n",
    "\n",
    "# Kiá»ƒm tra API keys\n",
    "print(f\"Tá»•ng sá»‘ API keys: {len(API_KEYS)}\")\n",
    "for i, key in enumerate(API_KEYS, 1):\n",
    "    print(f\"Key {i}: {key}\")\n",
    "\n",
    "NUM_THREADS = 6\n",
    "if len(API_KEYS) < NUM_THREADS:\n",
    "    raise ValueError(f\"âŒ Cáº§n Ã­t nháº¥t {NUM_THREADS} API keys, hiá»‡n táº¡i chá»‰ cÃ³ {len(API_KEYS)}.\")\n",
    "\n",
    "print(f\"{len(API_KEYS)} API keys Ä‘Æ°á»£c tÃ¬m tháº¥y.\")\n",
    "\n",
    "# Danh sÃ¡ch API keys bá»‹ vÃ´ hiá»‡u hÃ³a táº¡m thá»i\n",
    "disabled_api_keys = set()\n",
    "\n",
    "# KhÃ³a Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t khi ghi file vÃ  log\n",
    "file_lock = threading.Lock()\n",
    "log_lock = threading.Lock()\n",
    "\n",
    "# Chia API keys thÃ nh cÃ¡c nhÃ³m cho má»—i thread\n",
    "def split_api_keys(keys, num_threads):\n",
    "    active_keys = [key for key in keys if key not in disabled_api_keys]\n",
    "    if len(active_keys) < num_threads:\n",
    "        raise ValueError(f\"âŒ KhÃ´ng Ä‘á»§ API keys hoáº¡t Ä‘á»™ng, chá»‰ cÃ²n {len(active_keys)} key.\")\n",
    "    groups = [[] for _ in range(num_threads)]\n",
    "    for idx, key in enumerate(active_keys):\n",
    "        groups[idx % num_threads].append(key)\n",
    "    return groups\n",
    "\n",
    "api_key_groups = split_api_keys(API_KEYS, NUM_THREADS)\n",
    "\n",
    "# Cáº¥u hÃ¬nh thÆ° má»¥c vÃ  file log\n",
    "INPUT_FOLDER = \"folder_2.5_step1_good\"\n",
    "OUTPUT_FOLDER = \"folder_2.5_step2\"\n",
    "LOG_FILE = \"step2_log.txt\"\n",
    "ERROR_LOG = \"new_error_log_step2.jsonl\"  # Log lá»—i má»›i Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t\n",
    "SUCCESS_LOG = \"success_log_step2.jsonl\"\n",
    "COMPLETE_LOG = \"complete_log_step2.jsonl\"  # Tá»« code xá»­ lÃ½\n",
    "INCOMPLETE_LOG = \"incomplete_log_step2.jsonl\"  # Tá»« code xá»­ lÃ½\n",
    "ERROR_LOG_PROCESS = \"error_log_step2.jsonl\"  # Tá»« code xá»­ lÃ½\n",
    "\n",
    "# Äá»‹nh nghÄ©a instruction\n",
    "INSTRUCTION = \"\"\"\n",
    "Báº¡n lÃ  má»™t há»‡ thá»‘ng táº¡o dá»¯ liá»‡u huáº¥n luyá»‡n cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) trong lÄ©nh vá»±c tÃ i chÃ­nh.\n",
    "Äáº§u vÃ o: danh sÃ¡ch cÃ¡c chunk dá»¯ liá»‡u vÃ  cÃ¢u há»i liÃªn quan, á»Ÿ dáº¡ng JSON:\n",
    "[\n",
    "{\n",
    "\"chunk_id\": 1,\n",
    "\"content\": \"Ná»™i dung chunk 1 ...\",\n",
    "\"questions\": [\n",
    "\"CÃ¢u há»i 1\",\n",
    "\"CÃ¢u há»i 2\"\n",
    "]\n",
    "},\n",
    "...\n",
    "]\n",
    "Nhiá»‡m vá»¥ cá»§a báº¡n:\n",
    "Vá»›i má»—i cÃ¢u há»i, Ä‘á»c ná»™i dung chunk tÆ°Æ¡ng á»©ng vÃ  tráº£ lá»i ngáº¯n gá»n, chÃ­nh xÃ¡c, Ä‘á»§ thÃ´ng tin.\n",
    "CÃ¢u tráº£ lá»i pháº£i dá»±a 100% vÃ o ná»™i dung chunk. Náº¿u thÃ´ng tin khÃ´ng tá»“n táº¡i trong chunk, tráº£ lá»i: \"ThÃ´ng tin khÃ´ng cÃ³ trong dá»¯ liá»‡u\", tuy nhiÃªn náº¿u cáº§n phÃ¢n tÃ­ch hÃ£y dÃ¹ng kiáº¿n thá»©c phÃ¢n tÃ­ch cá»§a báº¡n.\n",
    "Xuáº¥t káº¿t quáº£ á»Ÿ Ä‘á»‹nh dáº¡ng JSON Lines (má»—i dÃ²ng má»™t object), vá»›i cáº¥u trÃºc:\n",
    "[\n",
    "    {\n",
    "        \"instruction\": \"CÃ¢u há»i\",\n",
    "        \"input\": \"chunk_id\"(Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ chÃ¨n sau Ä‘Ã³ vÃ  báº¡n khÃ´ng bá»‹ quÃ¡ táº£i),\n",
    "        \"output\": \"CÃ¢u tráº£ lá»i\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "YÃªu cáº§u:\n",
    "Giá»¯ nguyÃªn Ä‘á»‹nh dáº¡ng báº£ng Markdown náº¿u cÃ³ trong \"input\".\n",
    "KhÃ´ng thÃªm thÃ´ng tin ngoÃ i chunk.\n",
    "NgÃ´n ngá»¯: tiáº¿ng Viá»‡t.\n",
    "Báº¯t Ä‘áº§u táº¡o dá»¯ liá»‡u instruction ngay sau Ä‘Ã¢y, Ä‘Ã¢y lÃ  chunk:\n",
    "\"\"\"\n",
    "\n",
    "# Táº¡o thÆ° má»¥c Ä‘áº§u ra náº¿u chÆ°a cÃ³\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# --- Logging ---\n",
    "def write_log(message, log_file=LOG_FILE):\n",
    "    with log_lock:\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            f.write(f\"[{timestamp}] {message}\\n\")\n",
    "\n",
    "def log_error(filename, api_key, error_message, error_type):\n",
    "    entry = {\n",
    "        \"file\": filename,\n",
    "        \"api_key\": api_key if api_key else \"N/A\",\n",
    "        \"error\": error_message,\n",
    "        \"error_type\": error_type,\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    with log_lock:\n",
    "        with open(ERROR_LOG, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def log_success(filename):\n",
    "    entry = {\n",
    "        \"file\": filename,\n",
    "        \"status\": \"GOOD\",\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    with log_lock:\n",
    "        with open(SUCCESS_LOG, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Äá»c nguyÃªn vÄƒn file JSON\n",
    "def read_json_file(json_path: Path):\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        if not content.strip():\n",
    "            raise ValueError(\"File JSON rá»—ng.\")\n",
    "        log_msg = f\"ğŸ“„ ÄÃ£ Ä‘á»c content tá»«: {json_path.name}\"\n",
    "        write_log(log_msg)\n",
    "        print(log_msg)\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ Lá»—i Ä‘á»c file JSON {json_path.name}: {str(e)}\"\n",
    "        write_log(error_msg)\n",
    "        print(error_msg)\n",
    "        log_error(json_path.name, None, str(e), \"FILE_READ_ERROR\")\n",
    "        return None\n",
    "\n",
    "# Gá»­i content lÃªn Gemini\n",
    "def ask_gemini_from_text(content, instruction, api_key):\n",
    "    full_prompt = f\"\"\"{instruction}\n",
    "------------------------------\n",
    "{content}\n",
    "\"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ Lá»—i gá»i Gemini API (key {api_key[:8]}...): {str(e)}\"\n",
    "        error_type = \"GEMINI_ERROR\"\n",
    "        if \"quota\" in str(e).lower() or \"rate limit\" in str(e).lower():\n",
    "            disabled_api_keys.add(api_key)\n",
    "            error_msg += f\" | API key {api_key[:8]}... bá»‹ vÃ´ hiá»‡u hÃ³a táº¡m thá»i do quota.\"\n",
    "            error_type = \"GEMINI_QUOTA_ERROR\"\n",
    "        return error_msg, error_type\n",
    "\n",
    "# LÆ°u káº¿t quáº£\n",
    "def save_output(json_path: Path, response, api_key):\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, json_path.name)\n",
    "    try:\n",
    "        if response.startswith(\"âŒ\"):\n",
    "            raise ValueError(response)\n",
    "        with file_lock:\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response)\n",
    "        log_msg = f\"âœ… LÆ°u file thÃ nh cÃ´ng: {output_path}\"\n",
    "        write_log(log_msg)\n",
    "        print(log_msg)\n",
    "        log_success(json_path.name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        log_msg = f\"âŒ Lá»—i lÆ°u file {output_path}: {str(e)}\"\n",
    "        write_log(log_msg)\n",
    "        print(log_msg)\n",
    "        log_error(json_path.name, api_key, str(e), \"FILE_WRITE_ERROR\")\n",
    "        return False\n",
    "\n",
    "# Load cÃ¡c file tá»« log xá»­ lÃ½ Ä‘á»ƒ cháº¡y láº¡i\n",
    "def get_files_to_retry():\n",
    "    files_to_retry = set()\n",
    "    for log_file in [INCOMPLETE_LOG, ERROR_LOG_PROCESS]:\n",
    "        if Path(log_file).exists():\n",
    "            with open(log_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    try:\n",
    "                        entry = json.loads(line)\n",
    "                        if entry[\"status\"] in [\"INCOMPLETE\", \"ERROR\"]:\n",
    "                            files_to_retry.add(entry[\"file\"])\n",
    "                    except:\n",
    "                        continue\n",
    "    return list(files_to_retry)\n",
    "\n",
    "# Láº¥y file chÆ°a xá»­ lÃ½ hoáº·c cáº§n retry\n",
    "def get_unprocessed_json_files():\n",
    "    json_files = set(Path(INPUT_FOLDER).glob(\"*.json\"))\n",
    "    output_files = set(Path(OUTPUT_FOLDER).glob(\"*.json\"))\n",
    "    complete_files = set()\n",
    "    if Path(COMPLETE_LOG).exists():\n",
    "        with open(COMPLETE_LOG, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    entry = json.loads(line)\n",
    "                    if entry[\"status\"] == \"COMPLETE\":\n",
    "                        complete_files.add(entry[\"file\"])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    # File chÆ°a xá»­ lÃ½: cÃ³ trong folder_1_step1_good nhÆ°ng khÃ´ng cÃ³ trong folder_1_step2_final\n",
    "    unprocessed = [f for f in json_files if f.name not in output_files]\n",
    "    \n",
    "    # File cáº§n retry: INCOMPLETE hoáº·c ERROR tá»« log xá»­ lÃ½\n",
    "    retry_files = get_files_to_retry()\n",
    "    retry_paths = [Path(INPUT_FOLDER) / f for f in retry_files if (Path(INPUT_FOLDER) / f).exists() and f not in complete_files]\n",
    "    \n",
    "    # Káº¿t há»£p vÃ  loáº¡i bá» file Ä‘Ã£ hoÃ n thiá»‡n\n",
    "    all_to_process = list(set(unprocessed + retry_paths))\n",
    "    all_to_process = [f for f in all_to_process if f.name not in complete_files]\n",
    "    \n",
    "    # Ghi log tÃ³m táº¯t\n",
    "    write_log(f\"ğŸ“‚ Tá»•ng file input tá»‘t ({INPUT_FOLDER}): {len(json_files)}\")\n",
    "    write_log(f\"ğŸ“‚ File Ä‘Ã£ cÃ³ trong {OUTPUT_FOLDER}: {len(output_files)}\")\n",
    "    write_log(f\"ğŸ“‚ File hoÃ n thiá»‡n theo {COMPLETE_LOG}: {len(complete_files)}\")\n",
    "    write_log(f\"âš ï¸ File chÆ°a xá»­ lÃ½: {len(unprocessed)}\")\n",
    "    if unprocessed:\n",
    "        display_unprocessed = [f.name for f in unprocessed][:10]\n",
    "        if len(unprocessed) > 10:\n",
    "            display_unprocessed.append(\"... (vÃ  thÃªm)\")\n",
    "        write_log(f\"   - Danh sÃ¡ch file chÆ°a xá»­ lÃ½: {', '.join(display_unprocessed)}\")\n",
    "    write_log(f\"âš ï¸ File cáº§n retry (INCOMPLETE/ERROR): {len(retry_paths)}\")\n",
    "    if retry_paths:\n",
    "        display_retry = [f.name for f in retry_paths][:10]\n",
    "        if len(retry_paths) > 10:\n",
    "            display_retry.append(\"... (vÃ  thÃªm)\")\n",
    "        write_log(f\"   - Danh sÃ¡ch file retry: {', '.join(display_retry)}\")\n",
    "\n",
    "    return all_to_process\n",
    "\n",
    "# Xá»­ lÃ½ má»™t file JSON\n",
    "def process_json_file(json_file: Path, api_keys_cycle: cycle):\n",
    "    print(f\"\\nğŸ“ Äang xá»­ lÃ½: {json_file.name}\")\n",
    "    file_content = read_json_file(json_file)\n",
    "    if not file_content:\n",
    "        return\n",
    "\n",
    "    success = False\n",
    "    active_keys = [key for key in API_KEYS if key not in disabled_api_keys]\n",
    "    if len(active_keys) == 0:\n",
    "        write_log(f\"âŒ KhÃ´ng cÃ²n API key hoáº¡t Ä‘á»™ng nÃ o, dá»«ng xá»­ lÃ½ {json_file.name}\")\n",
    "        return\n",
    "\n",
    "    for api_key in cycle(active_keys):\n",
    "        if len([k for k in API_KEYS if k not in disabled_api_keys]) < NUM_THREADS:\n",
    "            write_log(f\"âŒ Sá»‘ API key hoáº¡t Ä‘á»™ng dÆ°á»›i {NUM_THREADS}, dá»«ng xá»­ lÃ½ {json_file.name}\")\n",
    "            break\n",
    "\n",
    "        result = ask_gemini_from_text(file_content, INSTRUCTION, api_key)\n",
    "        if isinstance(result, tuple):\n",
    "            response, error_type = result\n",
    "            log_error(json_file.name, api_key, response, error_type)\n",
    "            write_log(f\"âš ï¸ Lá»—i vá»›i key {api_key[:8]}... cho {json_file.name}: {response}\")\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            if save_output(json_file, result, api_key):\n",
    "                success = True\n",
    "                break\n",
    "\n",
    "    if not success:\n",
    "        write_log(f\"âŒ Bá» qua {json_file.name} sau khi thá»­ táº¥t cáº£ key hoáº¡t Ä‘á»™ng.\")\n",
    "    file_content = None\n",
    "\n",
    "# Chia file cho cÃ¡c thread\n",
    "def assign_jsons_to_threads(json_files, num_threads):\n",
    "    assigned = [[] for _ in range(num_threads)]\n",
    "    for idx, json_file in enumerate(json_files):\n",
    "        assigned[idx % num_threads].append(json_file)\n",
    "    return assigned\n",
    "\n",
    "# Xá»­ lÃ½ song song\n",
    "def process_all_jsons_concurrently(max_workers=NUM_THREADS):\n",
    "    json_files = get_unprocessed_json_files()\n",
    "    if not json_files:\n",
    "        write_log(f\"ğŸ“‚ KhÃ´ng cÃ³ file JSON nÃ o chÆ°a xá»­ lÃ½ hoáº·c cáº§n retry trong thÆ° má»¥c {INPUT_FOLDER}.\")\n",
    "        return\n",
    "\n",
    "    write_log(f\"ğŸš€ Tá»•ng sá»‘ file cáº§n xá»­ lÃ½: {len(json_files)}\")\n",
    "    print(f\"ğŸš€ Tá»•ng sá»‘ file cáº§n xá»­ lÃ½: {len(json_files)}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    thread_json_lists = assign_jsons_to_threads(json_files, max_workers)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for i in range(max_workers):\n",
    "            json_list = thread_json_lists[i]\n",
    "            api_keys_cycle = cycle(api_key_groups[i])\n",
    "            for json_file in json_list:\n",
    "                futures.append(executor.submit(process_json_file, json_file, api_keys_cycle))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            _ = future.result()\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    write_log(f\"â±ï¸ Xong! Tá»•ng thá»i gian: {elapsed_time:.2f} giÃ¢y\")\n",
    "    print(f\"â±ï¸ Xong! Tá»•ng thá»i gian: {elapsed_time:.2f} giÃ¢y\")\n",
    "\n",
    "# Cháº¡y chÆ°Æ¡ng trÃ¬nh\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_jsons_concurrently(max_workers=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1396c6",
   "metadata": {},
   "source": [
    "### Kiá»ƒm tra vÃ  lá»c ra file tá»‘t tá»« bÆ°á»›c 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e87c2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459170_EN__SeparateFinancialStatements_Q4_2024.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json\n",
      "\n",
      "ğŸ“ Äang xá»­ lÃ½: 000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Cáº¥u hÃ¬nh thÆ° má»¥c vÃ  file log\n",
    "INPUT_FOLDER = \"folder_2.5_step2\"\n",
    "OUTPUT_FOLDER = \"folder_2.5_step2_cleaned\"\n",
    "INPUT_GOOD_FOLDER = \"folder_2.5_step1_good\"\n",
    "COMPLETE_LOG = \"complete_log_step2.jsonl\"\n",
    "INCOMPLETE_LOG = \"incomplete_log_step2.jsonl\"\n",
    "ERROR_LOG = \"error_log_step2.jsonl\"\n",
    "SUMMARY_LOG = \"summary_log_step2.txt\"\n",
    "\n",
    "# Táº¡o thÆ° má»¥c Ä‘áº§u ra náº¿u chÆ°a cÃ³\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# --- Logging ---\n",
    "def write_summary_log(message, log_file=SUMMARY_LOG):\n",
    "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "\n",
    "def log_complete(filename, num_items):\n",
    "    entry = {\n",
    "        \"file\": filename,\n",
    "        \"status\": \"COMPLETE\",\n",
    "        \"num_items\": num_items,\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    with open(COMPLETE_LOG, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "    write_summary_log(f\"âœ… HoÃ n thiá»‡n file: {filename} (sá»‘ item: {num_items})\")\n",
    "\n",
    "def log_incomplete(filename, content, reason):\n",
    "    entry = {\n",
    "        \"file\": filename,\n",
    "        \"status\": \"INCOMPLETE\",\n",
    "        \"length\": len(content) if isinstance(content, str) else 0,\n",
    "        \"reason\": reason,\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    with open(INCOMPLETE_LOG, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "    write_summary_log(f\"âš ï¸ ChÆ°a hoÃ n thiá»‡n file: {filename} (lÃ½ do: {reason})\")\n",
    "\n",
    "def log_error(filename, error_message):\n",
    "    entry = {\n",
    "        \"file\": filename,\n",
    "        \"status\": \"ERROR\",\n",
    "        \"error\": error_message,\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    with open(ERROR_LOG, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "    write_summary_log(f\"âŒ Lá»—i file: {filename} (lá»—i: {error_message})\")\n",
    "\n",
    "# --- JSON Processing ---\n",
    "def clean_output_field(output_text):\n",
    "    \"\"\"Loáº¡i bá» dáº¥u ngoáº·c kÃ©p bao quanh cÃ¡c cá»¥m tá»« trong trÆ°á»ng output.\"\"\"\n",
    "    def replace_quoted(match):\n",
    "        quoted_text = match.group(1)\n",
    "        if '\"' not in quoted_text:\n",
    "            return quoted_text\n",
    "        return match.group(0)  # Giá»¯ nguyÃªn náº¿u cÃ³ dáº¥u ngoáº·c kÃ©p bÃªn trong\n",
    "    cleaned_text = re.sub(r'\"([^\"]*)\"', replace_quoted, output_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def parse_and_clean_dict_str(dict_str):\n",
    "    \"\"\"Parse thá»§ cÃ´ng dict_str Ä‘á»ƒ extract fields, clean output, rá»“i rebuild dÃ¹ng json.dumps.\"\"\"\n",
    "    dict_str = dict_str.strip()\n",
    "\n",
    "    # Extract instruction (giáº£ Ä‘á»‹nh khÃ´ng cÃ³ \" bÃªn trong)\n",
    "    instr_match = re.search(r'\"instruction\"\\s*:\\s*\"([^\"]*)\"', dict_str)\n",
    "    if not instr_match:\n",
    "        return None\n",
    "    instruction = instr_match.group(1)\n",
    "\n",
    "    # Extract input (giáº£ Ä‘á»‹nh khÃ´ng cÃ³ \" bÃªn trong)\n",
    "    input_match = re.search(r'\"input\"\\s*:\\s*\"([^\"]*)\"', dict_str)\n",
    "    if not input_match:\n",
    "        return None\n",
    "    input_val = input_match.group(1)\n",
    "\n",
    "    # Extract output: tá»« sau \"output\": \" Ä‘áº¿n trÆ°á»›c \" cuá»‘i cÃ¹ng trÆ°á»›c }\n",
    "    output_pos = dict_str.find('\"output\"')\n",
    "    if output_pos == -1:\n",
    "        return None\n",
    "\n",
    "    colon_pos = dict_str.find(':', output_pos)\n",
    "    value_start = dict_str.find('\"', colon_pos)\n",
    "    if value_start == -1:\n",
    "        return None\n",
    "\n",
    "    end_pos = dict_str.rfind('}')\n",
    "    if end_pos == -1:\n",
    "        return None\n",
    "\n",
    "    value_end = dict_str.rfind('\"', 0, end_pos)\n",
    "    if value_end == -1 or value_end <= value_start:\n",
    "        return None\n",
    "\n",
    "    output_value = dict_str[value_start + 1 : value_end]\n",
    "\n",
    "    # Clean output\n",
    "    cleaned_output = clean_output_field(output_value)\n",
    "\n",
    "    # Táº¡o dict Python\n",
    "    data_dict = {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": input_val,\n",
    "        \"output\": cleaned_output\n",
    "    }\n",
    "\n",
    "    # Rebuild thÃ nh chuá»—i JSON\n",
    "    try:\n",
    "        new_dict_str = json.dumps(data_dict, ensure_ascii=False)\n",
    "        return new_dict_str\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_json_block(content):\n",
    "    if \"```json\" in content and \"```\" not in content.split(\"```json\")[1]:\n",
    "        incomplete_content = content.split(\"```json\")[1].strip()\n",
    "        return incomplete_content, False, True, \"Khá»‘i ```json``` khÃ´ng Ä‘Ã³ng\"\n",
    "\n",
    "    extracted = re.search(r\"```json\\s*(.*?)\\s*```\", content, re.DOTALL)\n",
    "    if extracted:\n",
    "        json_content = extracted.group(1).strip()\n",
    "        dicts, is_complete = extract_complete_dicts(json_content)\n",
    "        reason = \"JSON bá»‹ ngáº¯t giá»¯a chá»«ng trong khá»‘i ```json```\" if not is_complete else None\n",
    "        if dicts:\n",
    "            return dicts, is_complete, True, reason\n",
    "        return json_content, is_complete, True, reason\n",
    "    return content, True, False, None\n",
    "\n",
    "def extract_complete_dicts(raw_text):\n",
    "    \"\"\"TÃ¡ch cÃ¡c dict hoÃ n chá»‰nh tá»« chuá»—i text, vÃ  clean trÆ°á»›c khi validate.\"\"\"\n",
    "    dicts = []\n",
    "    stack = 0\n",
    "    start = None\n",
    "\n",
    "    for i, ch in enumerate(raw_text):\n",
    "        if ch == \"{\":\n",
    "            if stack == 0:\n",
    "                start = i\n",
    "            stack += 1\n",
    "        elif ch == \"}\":\n",
    "            stack -= 1\n",
    "            if stack == 0 and start is not None:\n",
    "                dict_str = raw_text[start:i+1]\n",
    "                # Clean vÃ  rebuild\n",
    "                cleaned_str = parse_and_clean_dict_str(dict_str)\n",
    "                if cleaned_str:\n",
    "                    try:\n",
    "                        json.loads(cleaned_str)\n",
    "                        dicts.append(cleaned_str)\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                start = None\n",
    "        elif stack < 0:\n",
    "            break\n",
    "\n",
    "    return dicts, stack == 0\n",
    "\n",
    "def validate_json_lines(data):\n",
    "    if not isinstance(data, list):\n",
    "        return False, \"Dá»¯ liá»‡u khÃ´ng pháº£i danh sÃ¡ch JSON\"\n",
    "    for item in data:\n",
    "        if not isinstance(item, dict) or not all(key in item for key in [\"instruction\", \"input\", \"output\"]):\n",
    "            return False, \"Object thiáº¿u cÃ¡c trÆ°á»ng instruction/input/output\"\n",
    "    return True, \"\"\n",
    "\n",
    "def process_json_file(json_file: Path):\n",
    "    print(f\"\\nğŸ“ Äang xá»­ lÃ½: {json_file.name}\")\n",
    "    try:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_content = f.read().strip()\n",
    "    except Exception as e:\n",
    "        log_error(json_file.name, f\"Lá»—i Ä‘á»c file: {str(e)}\")\n",
    "        return \"error\"\n",
    "\n",
    "    content, is_complete, in_json_block, ngat_reason = extract_json_block(raw_content)\n",
    "    if ngat_reason:\n",
    "        log_incomplete(json_file.name, raw_content, ngat_reason)\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(raw_content)\n",
    "        return \"incomplete\"\n",
    "\n",
    "    if isinstance(content, list):\n",
    "        json_str = \"[\" + \",\".join(content) + \"]\"\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            is_valid, reason = validate_json_lines(data)\n",
    "            if not is_valid:\n",
    "                log_incomplete(json_file.name, json_str, f\"Cáº¥u trÃºc JSON Lines khÃ´ng há»£p lá»‡: {reason}\")\n",
    "                output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(json_str)\n",
    "                return \"incomplete\"\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            log_complete(json_file.name, len(data))\n",
    "            if not is_complete and ngat_reason:\n",
    "                log_incomplete(json_file.name, raw_content, ngat_reason)\n",
    "            return \"complete\"\n",
    "        except json.JSONDecodeError as e:\n",
    "            log_incomplete(json_file.name, json_str, f\"Lá»—i parse cÃ¡c dict trong khá»‘i ```json```: {str(e)}\")\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(json_str)\n",
    "            return \"incomplete\"\n",
    "\n",
    "    content = content.replace('<br>', '\\n')\n",
    "\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        if isinstance(data, list):\n",
    "            is_valid, reason = validate_json_lines(data)\n",
    "            if not is_valid:\n",
    "                log_incomplete(json_file.name, content, f\"Cáº¥u trÃºc JSON Lines khÃ´ng há»£p lá»‡: {reason}\")\n",
    "                output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(content)\n",
    "                return \"incomplete\"\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            log_complete(json_file.name, len(data))\n",
    "            return \"complete\"\n",
    "        else:\n",
    "            data = [data]\n",
    "            is_valid, reason = validate_json_lines(data)\n",
    "            if not is_valid:\n",
    "                log_incomplete(json_file.name, content, f\"Cáº¥u trÃºc JSON Lines khÃ´ng há»£p lá»‡: {reason}\")\n",
    "                output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(content)\n",
    "                return \"incomplete\"\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            log_complete(json_file.name, len(data))\n",
    "            return \"complete\"\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    dicts, is_complete = extract_complete_dicts(content)\n",
    "    if dicts:\n",
    "        json_str = \"[\" + \",\".join(dicts) + \"]\"\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            is_valid, reason = validate_json_lines(data)\n",
    "            if not is_valid:\n",
    "                log_incomplete(json_file.name, json_str, f\"Cáº¥u trÃºc JSON Lines khÃ´ng há»£p lá»‡: {reason}\")\n",
    "                output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(json_str)\n",
    "                return \"incomplete\"\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            log_complete(json_file.name, len(data))\n",
    "            if not is_complete:\n",
    "                log_incomplete(json_file.name, content, \"JSON bá»‹ ngáº¯t giá»¯a chá»«ng\")\n",
    "            return \"complete\"\n",
    "        except json.JSONDecodeError as e:\n",
    "            log_incomplete(json_file.name, content, f\"Lá»—i parse cÃ¡c dict: {str(e)}\")\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "            return \"incomplete\"\n",
    "\n",
    "    log_error(json_file.name, \"KhÃ´ng tÃ¬m tháº¥y JSON hoáº·c dict há»£p lá»‡\")\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, json_file.name)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return \"error\"\n",
    "\n",
    "def compare_with_good_folder():\n",
    "    good_files = {f.name for f in Path(INPUT_GOOD_FOLDER).glob(\"*.json\")}\n",
    "    step2_files = {f.name for f in Path(INPUT_FOLDER).glob(\"*.json\")}\n",
    "\n",
    "    processed = list(step2_files)\n",
    "    not_processed = list(good_files - step2_files)\n",
    "\n",
    "    write_summary_log(f\"ğŸŒŸ Tá»•ng sá»‘ file input tá»‘t (folder_1_step1_good): {len(good_files)}\")\n",
    "    write_summary_log(f\"ğŸ“‚ Sá»‘ file Ä‘Ã£ xá»­ lÃ½ (cÃ³ trong {INPUT_FOLDER}): {len(processed)}\")\n",
    "    if processed:\n",
    "        display_processed = processed if len(processed) <= 10 else processed[:10] + [\"... (vÃ  thÃªm)\"]\n",
    "        write_summary_log(f\"   - Danh sÃ¡ch file Ä‘Ã£ xá»­ lÃ½: {', '.join(display_processed)}\")\n",
    "    write_summary_log(f\"âš ï¸ Sá»‘ file chÆ°a xá»­ lÃ½: {len(not_processed)}\")\n",
    "    if not_processed:\n",
    "        display_not = not_processed if len(not_processed) <= 10 else not_processed[:10] + [\"... (vÃ  thÃªm)\"]\n",
    "        write_summary_log(f\"   - Danh sÃ¡ch file chÆ°a xá»­ lÃ½: {', '.join(display_not)}\")\n",
    "\n",
    "    return len(processed), len(not_processed)\n",
    "\n",
    "def summarize_results(num_files, num_complete, num_incomplete, num_error):\n",
    "    write_summary_log(f\"ğŸ“Š TÃ³m táº¯t xá»­ lÃ½ trong {INPUT_FOLDER}:\")\n",
    "    write_summary_log(f\"   - Tá»•ng file: {num_files}\")\n",
    "    write_summary_log(f\"   - HoÃ n thiá»‡n: {num_complete}\")\n",
    "    write_summary_log(f\"   - ChÆ°a hoÃ n thiá»‡n: {num_incomplete}\")\n",
    "    write_summary_log(f\"   - Lá»—i: {num_error}\")\n",
    "\n",
    "def process_all_files():\n",
    "    num_processed, num_not_processed = compare_with_good_folder()\n",
    "\n",
    "    files = list(Path(INPUT_FOLDER).glob(\"*.json\"))\n",
    "    if not files:\n",
    "        write_summary_log(\"ğŸ“‚ KhÃ´ng cÃ³ file JSON nÃ o trong thÆ° má»¥c.\")\n",
    "        return\n",
    "\n",
    "    write_summary_log(f\"ğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ {len(files)} file\")\n",
    "\n",
    "    start = time.time()\n",
    "    num_complete = 0\n",
    "    num_incomplete = 0\n",
    "    num_error = 0\n",
    "\n",
    "    for json_file in files:\n",
    "        status = process_json_file(json_file)\n",
    "        if status == \"complete\":\n",
    "            num_complete += 1\n",
    "        elif status == \"incomplete\":\n",
    "            num_incomplete += 1\n",
    "        elif status == \"error\":\n",
    "            num_error += 1\n",
    "\n",
    "    summarize_results(len(files), num_complete, num_incomplete, num_error)\n",
    "\n",
    "    write_summary_log(f\"â±ï¸ HoÃ n táº¥t sau {time.time() - start:.2f} giÃ¢y\")\n",
    "\n",
    "# --- Run ---\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39537912",
   "metadata": {},
   "source": [
    "### Code merge Ä‘á»ƒ táº¡o instruction data cuá»‘i cÃ¹ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b54d06a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] {\"file\": null, \"status\": \"INFO\", \"reason\": \"TÃ¬m tháº¥y 4 file chung Ä‘á»ƒ xá»­ lÃ½: 000000014459170_EN__SeparateFinancialStatements_Q4_2024, 000000014459180_EN_SeperateFinancialStatements_Q4_2024KS, 000000014459316_BCTC_Quy_4.2024__Cong_ty_Me, 000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024\", \"timestamp\": \"2025-09-09 01:15:24\"}\n",
      "[LOG] {\"file\": \"000000014459180_EN_SeperateFinancialStatements_Q4_2024KS.json\", \"status\": \"SUCCESS\", \"num_chunks\": 20, \"timestamp\": \"2025-09-09 01:15:24\"}\n",
      "[LOG] {\"file\": \"000000014459666_EN_The_Consolidated_financial_statements_for_the_fourth_quarter_of_2024.json\", \"status\": \"SUCCESS\", \"num_chunks\": 25, \"timestamp\": \"2025-09-09 01:15:24\"}\n",
      "[LOG] {\"file\": \"000000014459316_BCTC_Quy_4.2024__Cong_ty_Me.json\", \"status\": \"SUCCESS\", \"num_chunks\": 24, \"timestamp\": \"2025-09-09 01:15:24\"}\n",
      "[LOG] {\"file\": \"000000014459170_EN__SeparateFinancialStatements_Q4_2024.json\", \"status\": \"SUCCESS\", \"num_chunks\": 22, \"timestamp\": \"2025-09-09 01:15:24\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Cáº¥u hÃ¬nh thÆ° má»¥c\n",
    "STEP1_FOLDER = \"folder_2.5_step1_good\"\n",
    "STEP2_FOLDER = \"folder_2.5_step2_cleaned\"\n",
    "OUTPUT_FOLDER = \"instruction_data_2.5_final\"\n",
    "ERROR_FOLDER = \"instruction_data_2.5_error\"\n",
    "COMPLETE_LOG = \"complete_log_step2.jsonl\"\n",
    "LOG_FILE = \"instruction_data_log.jsonl\"\n",
    "\n",
    "# Táº¡o thÆ° má»¥c Ä‘áº§u ra náº¿u chÆ°a cÃ³\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# HÃ m ghi vÃ  in log\n",
    "def write_and_print_log(entry, log_file=LOG_FILE):\n",
    "    entry[\"timestamp\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_str = json.dumps(entry, ensure_ascii=False)\n",
    "    print(f\"[LOG] {log_str}\")\n",
    "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(log_str + \"\\n\")\n",
    "\n",
    "# HÃ m láº¥y danh sÃ¡ch file hoÃ n thiá»‡n tá»« complete_log_step2.jsonl\n",
    "def get_complete_files():\n",
    "    complete_files = set()\n",
    "    if not os.path.exists(COMPLETE_LOG):\n",
    "        write_and_print_log({\n",
    "            \"file\": None,\n",
    "            \"status\": \"ERROR\",\n",
    "            \"reason\": f\"KhÃ´ng tÃ¬m tháº¥y file log {COMPLETE_LOG}\"\n",
    "        })\n",
    "        return complete_files\n",
    "    try:\n",
    "        with open(COMPLETE_LOG, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                entry = json.loads(line.strip())\n",
    "                if entry.get(\"status\") == \"COMPLETE\":\n",
    "                    complete_files.add(entry[\"file\"])\n",
    "    except Exception as e:\n",
    "        write_and_print_log({\n",
    "            \"file\": None,\n",
    "            \"status\": \"ERROR\",\n",
    "            \"reason\": f\"Lá»—i Ä‘á»c file log {COMPLETE_LOG}: {str(e)}\"\n",
    "        })\n",
    "    return complete_files\n",
    "\n",
    "# HÃ m xá»­ lÃ½ má»™t file tá»« step1 vÃ  step2\n",
    "def process_files(step1_path: Path, step2_path: Path):\n",
    "    filename = step1_path.stem\n",
    "    try:\n",
    "        # Load data tá»« step1\n",
    "        with open(step1_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            step1_data = json.load(f)\n",
    "        if not isinstance(step1_data, list):\n",
    "            raise ValueError(\"Step1 data khÃ´ng pháº£i danh sÃ¡ch\")\n",
    "\n",
    "        # Load data tá»« step2\n",
    "        with open(step2_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            step2_data = json.load(f)\n",
    "        if not isinstance(step2_data, list):\n",
    "            raise ValueError(\"Step2 data khÃ´ng pháº£i danh sÃ¡ch\")\n",
    "\n",
    "        # Táº¡o dictionary answers theo chunk_id\n",
    "        answers_by_chunk = {}\n",
    "        for item in step2_data:\n",
    "            chunk_id = str(item.get(\"input\"))  # Äáº£m báº£o lÃ  string\n",
    "            instruction = item.get(\"instruction\")\n",
    "            output = item.get(\"output\")\n",
    "            if chunk_id not in answers_by_chunk:\n",
    "                answers_by_chunk[chunk_id] = []\n",
    "            answers_by_chunk[chunk_id].append({\"instruction\": instruction, \"output\": output})\n",
    "\n",
    "        # Xá»­ lÃ½ tá»«ng chunk trong step1\n",
    "        output_data = []\n",
    "        for chunk in step1_data:\n",
    "            chunk_id = str(chunk.get(\"chunk_id\"))  # Äáº£m báº£o lÃ  string\n",
    "            content = chunk.get(\"content\")\n",
    "            questions = chunk.get(\"questions\", [])\n",
    "\n",
    "            if not questions:\n",
    "                write_and_print_log({\n",
    "                    \"file\": filename,\n",
    "                    \"chunk_id\": chunk_id,\n",
    "                    \"status\": \"ERROR\",\n",
    "                    \"reason\": \"KhÃ´ng cÃ³ questions trong chunk\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Thu tháº­p danh sÃ¡ch instruction (questions) vÃ  difficulty\n",
    "            instr_list = [q[\"question\"] for q in questions]\n",
    "            diff_list = [q[\"difficulty\"] for q in questions]\n",
    "\n",
    "            # Láº¥y answers tá»« step2\n",
    "            chunk_answers = answers_by_chunk.get(chunk_id, [])\n",
    "            out_list = []\n",
    "            unmatched = []\n",
    "            for ans_item in chunk_answers:\n",
    "                if ans_item[\"instruction\"] in instr_list:\n",
    "                    idx = instr_list.index(ans_item[\"instruction\"])\n",
    "                    out_list.append((idx, ans_item[\"output\"]))\n",
    "                else:\n",
    "                    unmatched.append(ans_item[\"instruction\"])\n",
    "\n",
    "            if unmatched:\n",
    "                write_and_print_log({\n",
    "                    \"file\": filename,\n",
    "                    \"chunk_id\": chunk_id,\n",
    "                    \"status\": \"WARNING\",\n",
    "                    \"reason\": f\"CÃ¡c instruction khÃ´ng khá»›p: {unmatched}\"\n",
    "                })\n",
    "\n",
    "            # Sáº¯p xáº¿p out_list theo thá»© tá»± questions\n",
    "            out_list.sort(key=lambda x: x[0])\n",
    "            out_list = [o[1] for o in out_list]\n",
    "\n",
    "            # Kiá»ƒm tra sá»‘ lÆ°á»£ng\n",
    "            if len(instr_list) != len(out_list):\n",
    "                write_and_print_log({\n",
    "                    \"file\": filename,\n",
    "                    \"chunk_id\": chunk_id,\n",
    "                    \"status\": \"ERROR\",\n",
    "                    \"reason\": f\"Sá»‘ lÆ°á»£ng questions ({len(instr_list)}) khÃ´ng khá»›p vá»›i outputs ({len(out_list)})\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Táº¡o object má»›i\n",
    "            new_item = {\n",
    "                \"instruction\": instr_list,\n",
    "                \"input\": content,\n",
    "                \"output\": out_list,\n",
    "                \"difficulty\": diff_list\n",
    "            }\n",
    "            output_data.append(new_item)\n",
    "\n",
    "        if not output_data:\n",
    "            write_and_print_log({\n",
    "                \"file\": f\"{filename}.json\",\n",
    "                \"status\": \"ERROR\",\n",
    "                \"reason\": \"KhÃ´ng cÃ³ chunk nÃ o há»£p lá»‡\"\n",
    "            })\n",
    "            return\n",
    "\n",
    "        # LÆ°u output\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, f\"{filename}.json\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "        write_and_print_log({\n",
    "            \"file\": f\"{filename}.json\",\n",
    "            \"status\": \"SUCCESS\",\n",
    "            \"num_chunks\": len(output_data)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        write_and_print_log({\n",
    "            \"file\": f\"{filename}.json\",\n",
    "            \"status\": \"ERROR\",\n",
    "            \"reason\": str(e)\n",
    "        })\n",
    "\n",
    "# HÃ m xá»­ lÃ½ toÃ n bá»™\n",
    "def process_all_files():\n",
    "    # Láº¥y danh sÃ¡ch file hoÃ n thiá»‡n tá»« complete_log_step2.jsonl\n",
    "    complete_files = get_complete_files()\n",
    "    if not complete_files:\n",
    "        write_and_print_log({\n",
    "            \"file\": None,\n",
    "            \"status\": \"INFO\",\n",
    "            \"reason\": \"KhÃ´ng cÃ³ file nÃ o hoÃ n thiá»‡n trong complete_log_step2.jsonl\"\n",
    "        })\n",
    "        return\n",
    "\n",
    "    # Chá»‰ láº¥y cÃ¡c file trong STEP1_FOLDER vÃ  STEP2_FOLDER cÃ³ tÃªn trong complete_files\n",
    "    step1_files = {f.stem: f for f in Path(STEP1_FOLDER).glob(\"*.json\") if f.name in complete_files}\n",
    "    step2_files = {f.stem: f for f in Path(STEP2_FOLDER).glob(\"*.json\") if f.name in complete_files}\n",
    "\n",
    "    # TÃ¬m cÃ¡c file chung\n",
    "    common_stems = set(step1_files.keys()) & set(step2_files.keys())\n",
    "    if not common_stems:\n",
    "        write_and_print_log({\n",
    "            \"file\": None,\n",
    "            \"status\": \"INFO\",\n",
    "            \"reason\": \"KhÃ´ng cÃ³ file chung giá»¯a step1 vÃ  step2 (trong danh sÃ¡ch complete)\"\n",
    "        })\n",
    "        return\n",
    "\n",
    "    write_and_print_log({\n",
    "        \"file\": None,\n",
    "        \"status\": \"INFO\",\n",
    "        \"reason\": f\"TÃ¬m tháº¥y {len(common_stems)} file chung Ä‘á»ƒ xá»­ lÃ½: {', '.join(sorted(common_stems))}\"\n",
    "    })\n",
    "\n",
    "    # Xá»­ lÃ½ cÃ¡c file\n",
    "    for stem in common_stems:\n",
    "        process_files(step1_files[stem], step2_files[stem])\n",
    "\n",
    "    # Log cÃ¡c file trong step2 khÃ´ng cÃ³ trong step1\n",
    "    missing_step1 = set(step2_files.keys()) - set(step1_files.keys())\n",
    "    for stem in missing_step1:\n",
    "        write_and_print_log({\n",
    "            \"file\": f\"{stem}.json\",\n",
    "            \"status\": \"ERROR\",\n",
    "            \"reason\": \"KhÃ´ng tÃ¬m tháº¥y file tÆ°Æ¡ng á»©ng trong step1\"\n",
    "        })\n",
    "\n",
    "    # Kiá»ƒm tra vÃ  xá»­ lÃ½ file lá»—i\n",
    "    error_files = set()\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        try:\n",
    "            with open(LOG_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    entry = json.loads(line.strip())\n",
    "                    if entry.get(\"status\") == \"ERROR\" and entry.get(\"file\"):\n",
    "                        file_name = entry[\"file\"]\n",
    "                        # Chuáº©n hÃ³a tÃªn file\n",
    "                        if not file_name.endswith(\".json\"):\n",
    "                            file_name = f\"{file_name}.json\"\n",
    "                        # Kiá»ƒm tra file tá»“n táº¡i trong OUTPUT_FOLDER\n",
    "                        file_path = os.path.join(OUTPUT_FOLDER, file_name)\n",
    "                        if os.path.exists(file_path):\n",
    "                            error_files.add(file_name)\n",
    "                        else:\n",
    "                            write_and_print_log({\n",
    "                                \"file\": file_name,\n",
    "                                \"status\": \"INFO\",\n",
    "                                \"reason\": f\"File lá»—i khÃ´ng tá»“n táº¡i trong {OUTPUT_FOLDER}, bá» qua copy/xÃ³a\"\n",
    "                            })\n",
    "        except Exception as e:\n",
    "            write_and_print_log({\n",
    "                \"file\": None,\n",
    "                \"status\": \"ERROR\",\n",
    "                \"reason\": f\"Lá»—i Ä‘á»c file log {LOG_FILE}: {str(e)}\"\n",
    "            })\n",
    "\n",
    "    if error_files:\n",
    "        print(\"\\nğŸ“› CÃ¡c file cÃ³ lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½:\")\n",
    "        for error_file in sorted(error_files):\n",
    "            print(f\"  - {error_file}\")\n",
    "        print(f\"\\nTá»•ng sá»‘ file lá»—i: {len(error_files)}\")\n",
    "\n",
    "        # Há»i ngÆ°á»i dÃ¹ng vá» viá»‡c copy file lá»—i\n",
    "        # response = input(\"\\nâ“ CÃ³ muá»‘n copy cÃ¡c file lá»—i sang thÆ° má»¥c 'instruction_data_error' khÃ´ng? (y/n): \").strip().lower()\n",
    "        response = 'y'\n",
    "        if response == 'y':\n",
    "            os.makedirs(ERROR_FOLDER, exist_ok=True)\n",
    "            for error_file in error_files:\n",
    "                src_path = os.path.join(OUTPUT_FOLDER, error_file)\n",
    "                dst_path = os.path.join(ERROR_FOLDER, error_file)\n",
    "                try:\n",
    "                    shutil.copy2(src_path, dst_path)\n",
    "                    write_and_print_log({\n",
    "                        \"file\": error_file,\n",
    "                        \"status\": \"INFO\",\n",
    "                        \"reason\": f\"ÄÃ£ copy file lá»—i sang {ERROR_FOLDER}\"\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    write_and_print_log({\n",
    "                        \"file\": error_file,\n",
    "                        \"status\": \"ERROR\",\n",
    "                        \"reason\": f\"Lá»—i khi copy file sang {ERROR_FOLDER}: {str(e)}\"\n",
    "                    })\n",
    "\n",
    "            # Há»i ngÆ°á»i dÃ¹ng vá» viá»‡c xÃ³a file lá»—i\n",
    "            # response = input(\"\\nâ“ CÃ³ muá»‘n xÃ³a cÃ¡c file lá»—i trong thÆ° má»¥c Ä‘Ã­ch ('instruction_data_final') khÃ´ng? (y/n): \").strip().lower()\n",
    "            response = 'y'\n",
    "            if response == 'y':\n",
    "                for error_file in error_files:\n",
    "                    file_path = os.path.join(OUTPUT_FOLDER, error_file)\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        write_and_print_log({\n",
    "                            \"file\": error_file,\n",
    "                            \"status\": \"INFO\",\n",
    "                            \"reason\": f\"ÄÃ£ xÃ³a file lá»—i khá»i {OUTPUT_FOLDER}\"\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        write_and_print_log({\n",
    "                            \"file\": error_file,\n",
    "                            \"status\": \"ERROR\",\n",
    "                            \"reason\": f\"Lá»—i khi xÃ³a file trong {OUTPUT_FOLDER}: {str(e)}\"\n",
    "                        })\n",
    "\n",
    "# Cháº¡y chÆ°Æ¡ng trÃ¬nh\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
